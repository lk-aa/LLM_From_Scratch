{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f565bbe9-511f-4652-a2e6-b7a7610d0769",
   "metadata": {},
   "source": [
    "# LLaMA原理精讲与架构复现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4683e0-aa5a-4cd9-83fb-47483e55115a",
   "metadata": {},
   "source": [
    "- llama3架构一览"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a875d-bac2-48d8-8e5f-bf2e995bd4c3",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2024LLM/06.png\" alt=\"描述文字\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92fc313a-5565-4bfc-856f-69ab9c9ee5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import struct\n",
    "import inspect\n",
    "import time\n",
    "\n",
    "import LMConfig\n",
    "from typing import Any, Optional, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from transformers import PreTrainedModel\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5433b869-7561-4c51-bd92-2ee54f6c012b",
   "metadata": {},
   "source": [
    "## 1. Embedding层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d180f-0582-4fa1-a89a-caca2f013277",
   "metadata": {},
   "source": [
    "在PyTorch中，`nn.Embedding`层是用于处理离散数据（如单词或类别）的关键组件，特别常见于自然语言处理（NLP）和推荐系统等任务。它的主要功能是将输入的整数索引映射到连续的高维向量空间中，即将**索引**转化为**嵌入向量**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74521489-a437-49bb-90b8-c9cce304072f",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.Embedding(num_embeddings, embedding_dim)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8086d52-1356-4c08-bd7a-690645291881",
   "metadata": {},
   "source": [
    "- **`num_embeddings`**: 嵌入表的大小，即词汇表的大小或类别数。它定义了有多少个不同的“离散输入”可以映射到嵌入向量。\n",
    "- **`embedding_dim`**: 每个离散输入（类别、单词等）将被映射到的连续向量的维度大小。\n",
    "\n",
    "`nn.Embedding`的输入通常是整数（类别索引或词汇索引），它会根据输入的索引从一个大小为 `(num_embeddings, embedding_dim)` 的查找表中检索出相应的嵌入向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3729b0d-1853-44a4-a7d9-71bc66a4d9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5522,  0.7179,  1.6805],\n",
      "        [ 2.1118,  0.2995,  0.4167],\n",
      "        [-0.6033, -0.4972, -1.6700]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义Embedding层\n",
    "embedding = nn.Embedding(10, 3)  # num_embeddings=10, embedding_dim=3\n",
    "\n",
    "# 输入索引\n",
    "input_indices = torch.tensor([1, 2, 3])\n",
    "\n",
    "# 获取嵌入向量\n",
    "output = embedding(input_indices)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed819352-91f7-4cbf-bffc-1600dac7bc24",
   "metadata": {},
   "source": [
    "- embedding层携带巨大的权重矩阵，是参数量计算的关键过程之一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e5bbd22-8688-47a9-a10b-ace33b7f7fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4752, -0.2457,  0.2101],\n",
      "        [ 1.5522,  0.7179,  1.6805],\n",
      "        [ 2.1118,  0.2995,  0.4167],\n",
      "        [-0.6033, -0.4972, -1.6700],\n",
      "        [-0.8719, -0.7207,  0.8305],\n",
      "        [ 1.2962, -1.2880,  0.8838],\n",
      "        [-0.7804, -0.1872,  0.3502],\n",
      "        [-0.2817, -0.9322,  0.5499],\n",
      "        [-0.5277,  0.8808, -1.6055],\n",
      "        [ 0.5706,  0.9455, -0.0734]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding.weight) #结构为10,3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a141f378-4d72-4619-85c5-5c618d97ffbe",
   "metadata": {},
   "source": [
    "## 2. RMSNorm 均方根层归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01961679-0892-4cb9-9129-ef4fd84b9fe3",
   "metadata": {},
   "source": [
    "在Transformer结构中，Layer Normalization（层归一化）是一个至关重要的部分，它是一种特定的归一化技术，与Batch Normalization（批归一化）不同，Layer Normalization不是对一个批次（batch）中的样本进行归一化，而是独立地对每个样本中的所有特征进行归一化（也就是对单一词向量、单一时间点的所有embedding维度进行归一化）。具体来说，对于每个样本，Layer Normalization会在特定层的所有激活上计算均值和方差，然后用这些统计量来归一化该样本的激活值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db92da-d07b-4bc6-a2b6-6557589a8e13",
   "metadata": {},
   "source": [
    "- **LN与BN的差别**\n",
    "\n",
    "BN 和 LN 的差别就在$u_i$和 $\\sigma_i$这里，前者在某一个 Batch 内统计某特定神经元节点的输出分布（跨样本），后者在某一次迭代更新中统计同一层内的所有神经元节点的输出分布（同一样本下）。\n",
    "![Alt text](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/image-29.png)\n",
    "\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2024LLM/19.png)\n",
    "\n",
    "> * NLP任务中经常会处理长度不同的句子，使用LN时可以不考虑其它样本的长度。<br><br>\n",
    "> * 在某些情况下，当可用的内存有限或者为了加速训练而使用更小的batch时，BN因为batch数量不足而受到了限制。<br><br>\n",
    "> * 在某些NLP任务和解码设置中，模型可能会一个接一个地处理序列中的元素，而不是一次处理整个batch。这样BN就不是很适用了。<br><br>\n",
    "> * 在Transformer模型中有很深的层次和自注意机制。通过对每一层的输入进行规范化，可以防止值的爆炸或消失，从而帮助模型更快地收敛。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad51cf-fa69-48f3-9e95-ee6d0d5d5c45",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2024LLM/08.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5428aac-c3d3-4edf-9564-7f87037b8302",
   "metadata": {},
   "source": [
    "- **LN与RMSNorm的差别**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa340c4-2a62-4a07-99a8-91bd170b9e23",
   "metadata": {},
   "source": [
    "**RMSNorm** 和 **普通 LayerNorm** 的主要区别在于归一化的计算方式：\n",
    "\n",
    "1. **归一化公式**：  \n",
    "   - **LayerNorm** 会对输入特征的均值和方差进行计算，然后用这些统计量对每个特征进行归一化。\n",
    "   - **RMSNorm** 只计算输入特征的均方根 (RMS, Root Mean Square)，而不考虑均值。因此，RMSNorm 去掉了均值的计算，直接利用每个特征的均方根进行归一化。\n",
    "<br><br>\n",
    "2. **计算简化**：  \n",
    "   - **LayerNorm** 需要同时计算均值和方差，涉及更多的计算步骤。\n",
    "   - **RMSNorm** 只需要计算输入的均方根，计算量更小。\n",
    "\n",
    "- **更少的计算开销**：由于去除了对均值的计算，RMSNorm 的计算开销相比 LayerNorm 更小，尤其在大规模模型中表现更为高效。\n",
    "- **训练稳定性**：RMSNorm 保留了归一化的效果，能够稳定训练过程，同时在某些场景下表现出更好的收敛性。\n",
    "- **适合大模型**：RMSNorm 因其简化的计算过程，特别适合像 LLaMA 这样的大模型，可以提高训练和推理的效率。\n",
    "- **统计概念不同**：均方根 (RMS) 是数据点平方的均值再开平方，表达的是数据的“绝对大小”，忽略了数据的符号，反映的是整体数据的幅度或能量，均值和方差则更多代表波动，更关注数据的分布，包括数据的中心位置和离散程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbe442-8ffa-4952-a2ac-ac411f5f1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(torch.nn.Module):\n",
    "    # 初始化函数，接受参数：\n",
    "    # dim: 归一化的维度大小\n",
    "    # eps: 防止除零的非常小的数值\n",
    "    def __init__(self, dim: int, eps: float):\n",
    "        super().__init__()  # 调用父类的初始化方法\n",
    "        self.eps = eps  # 将 eps 存储为类的属性\n",
    "        # 初始化可学习的参数 weight，初始值为全1，形状为(dim,)\n",
    "        # 这是每个维度的缩放系数\n",
    "        self.weight = nn.Parameter(torch.ones(dim))  \n",
    "\n",
    "    # 定义一个内部方法 _norm，用于对输入 x 进行归一化操作\n",
    "    def _norm(self, x):\n",
    "        # 使用平方的均值作为输入的标准差，并加上 eps 以防止除零\n",
    "        # torch.rsqrt 是计算平方根的倒数，即 1 / sqrt(x)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    # 定义前向传播的操作\n",
    "    def forward(self, x):\n",
    "        # 首先调用 _norm 方法对输入 x 进行归一化，并确保类型一致性\n",
    "        # x.float() 将输入转换为浮点数进行精度较高的计算\n",
    "        output = self._norm(x.float()).type_as(x)  \n",
    "        # 将归一化后的输出乘以可学习的参数 weight，调整每个维度的缩放\n",
    "        return output * self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a9621e-6427-471a-ab1e-d07baf701198",
   "metadata": {},
   "source": [
    "- 如何理解-1维度？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ca839c-dc38-49cf-b4be-dbe9609a6b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3789, 0.4490, 0.6182, 0.1384, 0.5848],\n",
      "         [0.7976, 0.8643, 0.7966, 0.5964, 0.8800],\n",
      "         [0.8810, 0.2698, 0.3346, 0.7024, 0.7164],\n",
      "         [0.9868, 0.3738, 0.9188, 0.5578, 0.1266]],\n",
      "\n",
      "        [[0.4285, 0.5041, 0.3655, 0.3673, 0.2554],\n",
      "         [0.7663, 0.9435, 0.7177, 0.1168, 0.0876],\n",
      "         [0.6517, 0.9947, 0.0471, 0.0100, 0.0264],\n",
      "         [0.6155, 0.2442, 0.3132, 0.5508, 0.4759]],\n",
      "\n",
      "        [[0.6578, 0.8285, 0.8856, 0.9596, 0.7464],\n",
      "         [0.9596, 0.8770, 0.2025, 0.1470, 0.7849],\n",
      "         [0.9045, 0.6325, 0.3705, 0.9188, 0.6412],\n",
      "         [0.3341, 0.2872, 0.3253, 0.0787, 0.4443]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建形状为(3, 4, 5)的Tensor\n",
    "exp = torch.rand(3, 4, 5)\n",
    "\n",
    "print(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c057c5-e47e-4d6a-97e7-8f62b801e199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.4353e-01, 2.0159e-01, 3.8222e-01, 1.9165e-02, 3.4198e-01],\n",
       "         [6.3617e-01, 7.4708e-01, 6.3457e-01, 3.5566e-01, 7.7436e-01],\n",
       "         [7.7610e-01, 7.2778e-02, 1.1193e-01, 4.9332e-01, 5.1321e-01],\n",
       "         [9.7382e-01, 1.3970e-01, 8.4418e-01, 3.1110e-01, 1.6026e-02]],\n",
       "\n",
       "        [[1.8362e-01, 2.5410e-01, 1.3358e-01, 1.3489e-01, 6.5224e-02],\n",
       "         [5.8726e-01, 8.9019e-01, 5.1510e-01, 1.3637e-02, 7.6694e-03],\n",
       "         [4.2477e-01, 9.8942e-01, 2.2207e-03, 9.9925e-05, 6.9445e-04],\n",
       "         [3.7878e-01, 5.9637e-02, 9.8112e-02, 3.0340e-01, 2.2645e-01]],\n",
       "\n",
       "        [[4.3276e-01, 6.8649e-01, 7.8420e-01, 9.2082e-01, 5.5707e-01],\n",
       "         [9.2077e-01, 7.6917e-01, 4.1018e-02, 2.1602e-02, 6.1610e-01],\n",
       "         [8.1816e-01, 4.0001e-01, 1.3730e-01, 8.4413e-01, 4.1109e-01],\n",
       "         [1.1164e-01, 8.2483e-02, 1.0579e-01, 6.1930e-03, 1.9739e-01]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.pow(2) #平方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071e93b7-bfef-4337-bda5-905e072e9480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2177],\n",
       "         [0.6296],\n",
       "         [0.3935],\n",
       "         [0.4570]],\n",
       "\n",
       "        [[0.1543],\n",
       "         [0.4028],\n",
       "         [0.2834],\n",
       "         [0.2133]],\n",
       "\n",
       "        [[0.6763],\n",
       "         [0.4737],\n",
       "         [0.5221],\n",
       "         [0.1007]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.pow(2).mean(-1, keepdim=True)\n",
    "#在最后一个维度，也就是d_model的维度求解均值\n",
    "#对文字数据来说等同于对每一个token上所有的列求解均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "134f81d2-bac3-4a4f-a73e-c5f17088edc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.pow(2).mean(-1, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6664e890-ffbe-45d1-a080-143982931775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.1433],\n",
       "         [1.2603],\n",
       "         [1.5942],\n",
       "         [1.4793]],\n",
       "\n",
       "        [[2.5459],\n",
       "         [1.5757],\n",
       "         [1.8783],\n",
       "         [2.1654]],\n",
       "\n",
       "        [[1.2160],\n",
       "         [1.4529],\n",
       "         [1.3839],\n",
       "         [3.1513]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rsqrt(exp.pow(2).mean(-1, keepdim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bac7ea-8725-4d1e-bff8-5e747f8fcd27",
   "metadata": {},
   "source": [
    "## 3. 旋转位置编码Rotary Positional Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8722d8a1-6160-44ec-b65d-c427567bf882",
   "metadata": {},
   "source": [
    "在 **LLaMA (Large Language Model Meta AI)** 中，使用了一种称为 **旋转位置编码** (RoPE, Rotary Position Embedding) 的技术来引入位置信息。这种编码方式不同于传统的固定位置编码或可学习的位置编码，通过使用**旋转矩阵**将位置信息嵌入到序列中。\n",
    "\n",
    "- 旋转位置编码 (RoPE) 的原理：\n",
    "RoPE 的核心思想是将**位置编码**嵌入到每个输入的特征维度中，而不是像传统的绝对位置编码那样为每个位置生成单独的向量。具体而言，RoPE将输入特征通过一个与位置相关的**旋转变换**，在不同位置上通过旋转不同角度来表达位置信息。\n",
    "\n",
    "1. **嵌入位置信息**：  \n",
    "   通过使用旋转矩阵，RoPE能够在同一特征空间中嵌入位置信息，并且这种旋转变换可以是连续的，使得模型可以处理不同长度的序列输入，而不依赖于绝对位置编码的长度限制。\n",
    "\n",
    "2. **特征维度的分组旋转**：  \n",
    "   RoPE 会将输入特征维度两两分组，并将每对特征维度进行角度旋转，旋转角度根据序列中的相对位置来调整。随着序列位置的变化，每个特征都会以不同的旋转角度进行变化，从而实现位置的编码。\n",
    "\n",
    "3. **优点**：\n",
    "   - **相对位置感知**：RoPE 自然具备相对位置感知能力（因为它具有一定的循环性），因此模型可以更好地处理较长序列中的相对位置信息。\n",
    "   - **长度灵活性**：相比于绝对位置编码，RoPE 可以更加灵活地处理不同长度的序列，而不会受到编码长度的限制。\n",
    "   - **平滑的位置信息传递**：通过旋转变换的方式嵌入位置信息，使得位置信息在整个特征空间中平滑地传递，避免了绝对位置编码的离散性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599125a4-3711-4d44-afd5-b52f641396a0",
   "metadata": {},
   "source": [
    "- **旋转位置编码的具体流程**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dcec8b-c22b-4e97-a603-c7bbc117afe5",
   "metadata": {},
   "source": [
    "**Rotary Positional Embedding**（旋转位置编码）的流程可以如下解释——\n",
    "1. **x1 和 x2 是 token 的原始编码值**。\n",
    "2. **θ1（theta1）** 是一个常数，为每两维度的编码设置。我们将[$\\theta_1, \\theta_2...\\theta_{d/2}$]这个序列总称为“频率”。\n",
    "3. **m 是 position（位置）**，表示当前 token 在序列中的位置。\n",
    "4. 通过**m * θ** 计算角度，并将 **x1 和 x2** 按照这个角度进行旋转，得到新的编码 **x'1 和 x'2**。\n",
    "\n",
    "这个过程的核心是通过旋转操作引入位置相关的信息，这种方法可以使得模型对相对位置更加敏感，同时保持旋转不变性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1521307c-45ff-4561-a62e-1b896a3561e5",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2024LLM/07.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc83909c-8745-4096-b030-9b9d398e839a",
   "metadata": {},
   "source": [
    "- **极坐标表示**\n",
    "\n",
    "**极坐标表示**是表示二维平面上点的一种方式，与我们常用的**直角坐标系**不同。在极坐标系中，一个点的位置由**模长**（半径）和**角度**来确定。\n",
    "- **直角坐标系**：一个点的位置用两个值 `(x, y)` 来表示，`x` 是水平轴（x轴）的距离，`y` 是垂直轴（y轴）的距离。\n",
    "- **极坐标系**：一个点的位置用两个值 `(r, θ)` 来表示，其中：\n",
    "  - **`r`** 是从原点到这个点的距离（模长或半径），它表示点到原点的距离。\n",
    "  - **`θ`** 是这个点与极轴（通常是正x轴）之间的夹角，称为**角度**或**方位角**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37fc4aa-2ac7-47c1-827a-5d3401862c73",
   "metadata": {},
   "source": [
    "- <font color=\"red\">**相对位置表示**</font>\n",
    "\n",
    "通过这样的旋转，不难发现一个现象——当两个token距离很近时，他们旋转后的向量之间的夹角也会是很小的锐角。当两个token距离很远时，他们旋转后的向量的夹角角度就会更大。在注意力机制计算的过程中，我们是会计算词向量之间的点积来判断token与token的相关性，而两个向量的夹角是锐角时，向量之间的相关性就强，两个向量的夹角越靠近直角时，向量之间的相关性就弱。在旋转位置编码中，距离差距越大、两个向量旋转后的角度越大，因此**旋转位置编码通过在自注意力机制中旋转查询和键向量，使得随着两个词之间距离增加时，两个词之间的注意力分数（点积值）会逐渐衰减，相关性会减弱**，这有助于更好地模拟自然语言中远距离词语关联度降低的现象。\n",
    "\n",
    "那如果两个词距离太远，出现钝角、甚至出现反向的锐角怎么办？当两个向量之间出现钝角时，其相关性也比直角时要强，更不要提反向锐角了！为了避免距离非常遥远的两个token之间反而相关性强，RoPE设计时内嵌了随相对距离增加点积递减的机制，那就是**在计算频率时，位置值越大的词拿到的频率越小**。尽管在极坐标上旋转有可能使一些远离的词向量“接近”或“反向”，但是由于RoPE对长距离的相对位置引入了额外的衰减因子，这种情况下即使形成了反向的锐角，点积值也会因为衰减而减少，从而降低它们的注意力权重。这种情况下，即便在极坐标下形成反向锐角、或者钝角，旋转引入的这种衰减效应也会防止这些词在计算中获得过高的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0caef00c-6b55-42b2-94dc-d194fa78735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义频率计算\n",
    "def precompute_pos_cis(dim: int, max_position: int, theta: float = 10000.0):\n",
    "    #频率\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "\n",
    "    #位置编码m\n",
    "    m = torch.arange(max_position, device=freqs.device)\n",
    "\n",
    "    #频率乘以位置编码、外积\n",
    "    freqs = torch.outer(m, freqs).float()\n",
    "\n",
    "    #\n",
    "    pos_cis = torch.polar(torch.ones_like(freqs), freqs)\n",
    "    \n",
    "    return pos_cis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ac0294-e800-4ef3-9883-3ca3e9088ca3",
   "metadata": {},
   "source": [
    "- **频率（theta序列）是如何计算的**？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8965fb7-d3ce-4c24-8451-1a036d6a1a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 32\n",
    "\n",
    "torch.arange(0, dim, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "924b81f6-ff2a-4d5e-8979-dfb4fd17726f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, dim, 2)[: (dim // 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5e99d8d-d9aa-4897-a5e1-39c12b678c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#举例，如果是奇数的话，会得到怎样的结果\n",
    "dim = 33\n",
    "\n",
    "torch.arange(0, dim, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44426bae-2774-4b07-9507-d9978fe3055f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, dim, 2)[: (dim // 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6d98c37-3c14-4d4d-9862-687e63024ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0625, 0.1250, 0.1875, 0.2500, 0.3125, 0.3750, 0.4375, 0.5000,\n",
       "        0.5625, 0.6250, 0.6875, 0.7500, 0.8125, 0.8750, 0.9375])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#除以原始维度进行归一化，将所有的数据压缩到[0,1]之间\n",
    "#并且，允许列编号越大的特征有更大的值\n",
    "(torch.arange(0, dim, 2)[: (dim // 2)].float() /dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59ddb770-726e-49a4-8bb7-993429aefb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 5.6234e-01, 3.1623e-01, 1.7783e-01, 1.0000e-01, 5.6234e-02,\n",
       "        3.1623e-02, 1.7783e-02, 1.0000e-02, 5.6234e-03, 3.1623e-03, 1.7783e-03,\n",
       "        1.0000e-03, 5.6234e-04, 3.1623e-04, 1.7783e-04])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/ (10000 ** (torch.arange(0, dim, 2)[: (dim // 2)].float() /dim))\n",
    "#指数函数，特征维度越大，频率越小"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa30723-6294-4d5b-ab81-b388981e3412",
   "metadata": {},
   "source": [
    "> 频率与维度的关系图（以position = 1为例）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec2ec9d6-797f-4671-a1fa-735de8613fc9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "theta = 10000.0\n",
    "dim = 128  # Example dimension size\n",
    "\n",
    "# Calculate freqs as per the formula\n",
    "freqs = 1.0 / (theta ** (np.arange(0, dim, 2)[: (dim // 2)] / dim))\n",
    "\n",
    "# Plotting the freqs\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(freqs, marker='o', linestyle='-', color='b', label='Freqs vs Dimension')\n",
    "plt.title(\"Change in freqs with increasing dimension\")\n",
    "plt.xlabel(\"Dimension\")\n",
    "plt.ylabel(\"Freqs\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1dba2562-1d75-408a-bc9e-d2458b6d9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.arange(36, device=freqs.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3123d12d-a595-4ca3-ab93-7eb603e0a5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6b4826f-c4b5-4d81-bbbb-adcaa6fd097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = 1/ (10000 ** (torch.arange(0, dim, 2)[: (dim // 2)].float() /dim))\n",
    "\n",
    "freqs = torch.outer(m, freqs).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d08e47dc-4b73-4d8c-8e2b-5aa02b2c3dd5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 5.6234e-01, 3.1623e-01, 1.7783e-01, 1.0000e-01, 5.6234e-02,\n",
       "         3.1623e-02, 1.7783e-02, 1.0000e-02, 5.6234e-03, 3.1623e-03, 1.7783e-03,\n",
       "         1.0000e-03, 5.6234e-04, 3.1623e-04, 1.7783e-04],\n",
       "        [2.0000e+00, 1.1247e+00, 6.3246e-01, 3.5566e-01, 2.0000e-01, 1.1247e-01,\n",
       "         6.3246e-02, 3.5566e-02, 2.0000e-02, 1.1247e-02, 6.3246e-03, 3.5566e-03,\n",
       "         2.0000e-03, 1.1247e-03, 6.3246e-04, 3.5566e-04],\n",
       "        [3.0000e+00, 1.6870e+00, 9.4868e-01, 5.3348e-01, 3.0000e-01, 1.6870e-01,\n",
       "         9.4868e-02, 5.3348e-02, 3.0000e-02, 1.6870e-02, 9.4868e-03, 5.3348e-03,\n",
       "         3.0000e-03, 1.6870e-03, 9.4868e-04, 5.3348e-04],\n",
       "        [4.0000e+00, 2.2494e+00, 1.2649e+00, 7.1131e-01, 4.0000e-01, 2.2494e-01,\n",
       "         1.2649e-01, 7.1131e-02, 4.0000e-02, 2.2494e-02, 1.2649e-02, 7.1131e-03,\n",
       "         4.0000e-03, 2.2494e-03, 1.2649e-03, 7.1131e-04],\n",
       "        [5.0000e+00, 2.8117e+00, 1.5811e+00, 8.8914e-01, 5.0000e-01, 2.8117e-01,\n",
       "         1.5811e-01, 8.8914e-02, 5.0000e-02, 2.8117e-02, 1.5811e-02, 8.8914e-03,\n",
       "         5.0000e-03, 2.8117e-03, 1.5811e-03, 8.8914e-04],\n",
       "        [6.0000e+00, 3.3740e+00, 1.8974e+00, 1.0670e+00, 6.0000e-01, 3.3740e-01,\n",
       "         1.8974e-01, 1.0670e-01, 6.0000e-02, 3.3740e-02, 1.8974e-02, 1.0670e-02,\n",
       "         6.0000e-03, 3.3740e-03, 1.8974e-03, 1.0670e-03],\n",
       "        [7.0000e+00, 3.9364e+00, 2.2136e+00, 1.2448e+00, 7.0000e-01, 3.9364e-01,\n",
       "         2.2136e-01, 1.2448e-01, 7.0000e-02, 3.9364e-02, 2.2136e-02, 1.2448e-02,\n",
       "         7.0000e-03, 3.9364e-03, 2.2136e-03, 1.2448e-03],\n",
       "        [8.0000e+00, 4.4987e+00, 2.5298e+00, 1.4226e+00, 8.0000e-01, 4.4987e-01,\n",
       "         2.5298e-01, 1.4226e-01, 8.0000e-02, 4.4987e-02, 2.5298e-02, 1.4226e-02,\n",
       "         8.0000e-03, 4.4987e-03, 2.5298e-03, 1.4226e-03],\n",
       "        [9.0000e+00, 5.0611e+00, 2.8460e+00, 1.6005e+00, 9.0000e-01, 5.0611e-01,\n",
       "         2.8460e-01, 1.6005e-01, 9.0000e-02, 5.0611e-02, 2.8461e-02, 1.6005e-02,\n",
       "         9.0000e-03, 5.0611e-03, 2.8461e-03, 1.6005e-03],\n",
       "        [1.0000e+01, 5.6234e+00, 3.1623e+00, 1.7783e+00, 1.0000e+00, 5.6234e-01,\n",
       "         3.1623e-01, 1.7783e-01, 1.0000e-01, 5.6234e-02, 3.1623e-02, 1.7783e-02,\n",
       "         1.0000e-02, 5.6234e-03, 3.1623e-03, 1.7783e-03],\n",
       "        [1.1000e+01, 6.1858e+00, 3.4785e+00, 1.9561e+00, 1.1000e+00, 6.1858e-01,\n",
       "         3.4785e-01, 1.9561e-01, 1.1000e-01, 6.1858e-02, 3.4785e-02, 1.9561e-02,\n",
       "         1.1000e-02, 6.1858e-03, 3.4785e-03, 1.9561e-03],\n",
       "        [1.2000e+01, 6.7481e+00, 3.7947e+00, 2.1339e+00, 1.2000e+00, 6.7481e-01,\n",
       "         3.7947e-01, 2.1339e-01, 1.2000e-01, 6.7481e-02, 3.7947e-02, 2.1339e-02,\n",
       "         1.2000e-02, 6.7481e-03, 3.7947e-03, 2.1339e-03],\n",
       "        [1.3000e+01, 7.3104e+00, 4.1110e+00, 2.3118e+00, 1.3000e+00, 7.3104e-01,\n",
       "         4.1110e-01, 2.3118e-01, 1.3000e-01, 7.3104e-02, 4.1110e-02, 2.3118e-02,\n",
       "         1.3000e-02, 7.3104e-03, 4.1110e-03, 2.3118e-03],\n",
       "        [1.4000e+01, 7.8728e+00, 4.4272e+00, 2.4896e+00, 1.4000e+00, 7.8728e-01,\n",
       "         4.4272e-01, 2.4896e-01, 1.4000e-01, 7.8728e-02, 4.4272e-02, 2.4896e-02,\n",
       "         1.4000e-02, 7.8728e-03, 4.4272e-03, 2.4896e-03],\n",
       "        [1.5000e+01, 8.4351e+00, 4.7434e+00, 2.6674e+00, 1.5000e+00, 8.4351e-01,\n",
       "         4.7434e-01, 2.6674e-01, 1.5000e-01, 8.4351e-02, 4.7434e-02, 2.6674e-02,\n",
       "         1.5000e-02, 8.4351e-03, 4.7434e-03, 2.6674e-03],\n",
       "        [1.6000e+01, 8.9975e+00, 5.0596e+00, 2.8452e+00, 1.6000e+00, 8.9975e-01,\n",
       "         5.0596e-01, 2.8452e-01, 1.6000e-01, 8.9975e-02, 5.0596e-02, 2.8452e-02,\n",
       "         1.6000e-02, 8.9975e-03, 5.0596e-03, 2.8452e-03],\n",
       "        [1.7000e+01, 9.5598e+00, 5.3759e+00, 3.0231e+00, 1.7000e+00, 9.5598e-01,\n",
       "         5.3759e-01, 3.0231e-01, 1.7000e-01, 9.5598e-02, 5.3759e-02, 3.0231e-02,\n",
       "         1.7000e-02, 9.5598e-03, 5.3759e-03, 3.0231e-03],\n",
       "        [1.8000e+01, 1.0122e+01, 5.6921e+00, 3.2009e+00, 1.8000e+00, 1.0122e+00,\n",
       "         5.6921e-01, 3.2009e-01, 1.8000e-01, 1.0122e-01, 5.6921e-02, 3.2009e-02,\n",
       "         1.8000e-02, 1.0122e-02, 5.6921e-03, 3.2009e-03],\n",
       "        [1.9000e+01, 1.0684e+01, 6.0083e+00, 3.3787e+00, 1.9000e+00, 1.0684e+00,\n",
       "         6.0083e-01, 3.3787e-01, 1.9000e-01, 1.0684e-01, 6.0083e-02, 3.3787e-02,\n",
       "         1.9000e-02, 1.0684e-02, 6.0083e-03, 3.3787e-03],\n",
       "        [2.0000e+01, 1.1247e+01, 6.3246e+00, 3.5566e+00, 2.0000e+00, 1.1247e+00,\n",
       "         6.3246e-01, 3.5566e-01, 2.0000e-01, 1.1247e-01, 6.3246e-02, 3.5566e-02,\n",
       "         2.0000e-02, 1.1247e-02, 6.3246e-03, 3.5566e-03],\n",
       "        [2.1000e+01, 1.1809e+01, 6.6408e+00, 3.7344e+00, 2.1000e+00, 1.1809e+00,\n",
       "         6.6408e-01, 3.7344e-01, 2.1000e-01, 1.1809e-01, 6.6408e-02, 3.7344e-02,\n",
       "         2.1000e-02, 1.1809e-02, 6.6408e-03, 3.7344e-03],\n",
       "        [2.2000e+01, 1.2372e+01, 6.9570e+00, 3.9122e+00, 2.2000e+00, 1.2372e+00,\n",
       "         6.9570e-01, 3.9122e-01, 2.2000e-01, 1.2372e-01, 6.9570e-02, 3.9122e-02,\n",
       "         2.2000e-02, 1.2372e-02, 6.9570e-03, 3.9122e-03],\n",
       "        [2.3000e+01, 1.2934e+01, 7.2732e+00, 4.0900e+00, 2.3000e+00, 1.2934e+00,\n",
       "         7.2732e-01, 4.0900e-01, 2.3000e-01, 1.2934e-01, 7.2732e-02, 4.0900e-02,\n",
       "         2.3000e-02, 1.2934e-02, 7.2732e-03, 4.0900e-03],\n",
       "        [2.4000e+01, 1.3496e+01, 7.5895e+00, 4.2679e+00, 2.4000e+00, 1.3496e+00,\n",
       "         7.5895e-01, 4.2679e-01, 2.4000e-01, 1.3496e-01, 7.5895e-02, 4.2679e-02,\n",
       "         2.4000e-02, 1.3496e-02, 7.5895e-03, 4.2679e-03],\n",
       "        [2.5000e+01, 1.4059e+01, 7.9057e+00, 4.4457e+00, 2.5000e+00, 1.4059e+00,\n",
       "         7.9057e-01, 4.4457e-01, 2.5000e-01, 1.4059e-01, 7.9057e-02, 4.4457e-02,\n",
       "         2.5000e-02, 1.4059e-02, 7.9057e-03, 4.4457e-03],\n",
       "        [2.6000e+01, 1.4621e+01, 8.2219e+00, 4.6235e+00, 2.6000e+00, 1.4621e+00,\n",
       "         8.2219e-01, 4.6235e-01, 2.6000e-01, 1.4621e-01, 8.2219e-02, 4.6235e-02,\n",
       "         2.6000e-02, 1.4621e-02, 8.2219e-03, 4.6235e-03],\n",
       "        [2.7000e+01, 1.5183e+01, 8.5381e+00, 4.8014e+00, 2.7000e+00, 1.5183e+00,\n",
       "         8.5382e-01, 4.8014e-01, 2.7000e-01, 1.5183e-01, 8.5382e-02, 4.8014e-02,\n",
       "         2.7000e-02, 1.5183e-02, 8.5382e-03, 4.8014e-03],\n",
       "        [2.8000e+01, 1.5746e+01, 8.8544e+00, 4.9792e+00, 2.8000e+00, 1.5746e+00,\n",
       "         8.8544e-01, 4.9792e-01, 2.8000e-01, 1.5746e-01, 8.8544e-02, 4.9792e-02,\n",
       "         2.8000e-02, 1.5746e-02, 8.8544e-03, 4.9792e-03],\n",
       "        [2.9000e+01, 1.6308e+01, 9.1706e+00, 5.1570e+00, 2.9000e+00, 1.6308e+00,\n",
       "         9.1706e-01, 5.1570e-01, 2.9000e-01, 1.6308e-01, 9.1706e-02, 5.1570e-02,\n",
       "         2.9000e-02, 1.6308e-02, 9.1706e-03, 5.1570e-03],\n",
       "        [3.0000e+01, 1.6870e+01, 9.4868e+00, 5.3348e+00, 3.0000e+00, 1.6870e+00,\n",
       "         9.4868e-01, 5.3348e-01, 3.0000e-01, 1.6870e-01, 9.4868e-02, 5.3348e-02,\n",
       "         3.0000e-02, 1.6870e-02, 9.4868e-03, 5.3348e-03],\n",
       "        [3.1000e+01, 1.7433e+01, 9.8031e+00, 5.5127e+00, 3.1000e+00, 1.7433e+00,\n",
       "         9.8031e-01, 5.5127e-01, 3.1000e-01, 1.7433e-01, 9.8031e-02, 5.5127e-02,\n",
       "         3.1000e-02, 1.7433e-02, 9.8031e-03, 5.5127e-03],\n",
       "        [3.2000e+01, 1.7995e+01, 1.0119e+01, 5.6905e+00, 3.2000e+00, 1.7995e+00,\n",
       "         1.0119e+00, 5.6905e-01, 3.2000e-01, 1.7995e-01, 1.0119e-01, 5.6905e-02,\n",
       "         3.2000e-02, 1.7995e-02, 1.0119e-02, 5.6905e-03],\n",
       "        [3.3000e+01, 1.8557e+01, 1.0436e+01, 5.8683e+00, 3.3000e+00, 1.8557e+00,\n",
       "         1.0436e+00, 5.8683e-01, 3.3000e-01, 1.8557e-01, 1.0436e-01, 5.8683e-02,\n",
       "         3.3000e-02, 1.8557e-02, 1.0436e-02, 5.8683e-03],\n",
       "        [3.4000e+01, 1.9120e+01, 1.0752e+01, 6.0461e+00, 3.4000e+00, 1.9120e+00,\n",
       "         1.0752e+00, 6.0462e-01, 3.4000e-01, 1.9120e-01, 1.0752e-01, 6.0461e-02,\n",
       "         3.4000e-02, 1.9120e-02, 1.0752e-02, 6.0461e-03],\n",
       "        [3.5000e+01, 1.9682e+01, 1.1068e+01, 6.2240e+00, 3.5000e+00, 1.9682e+00,\n",
       "         1.1068e+00, 6.2240e-01, 3.5000e-01, 1.9682e-01, 1.1068e-01, 6.2240e-02,\n",
       "         3.5000e-02, 1.9682e-02, 1.1068e-02, 6.2240e-03]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1fcf67bf-08d7-4cfa-b24a-f94b5f18176e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 256])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precompute_pos_cis(dim=512, max_position = 128, theta=10000).shape\n",
    "# (seq_len,d_model/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca811703-53ec-472a-a669-3e6d02a86eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000+0.0000e+00j,  1.0000+0.0000e+00j,  1.0000+0.0000e+00j,\n",
       "          ...,  1.0000+0.0000e+00j,  1.0000+0.0000e+00j,\n",
       "          1.0000+0.0000e+00j],\n",
       "        [ 0.5403+8.4147e-01j,  0.5697+8.2186e-01j,  0.5974+8.0196e-01j,\n",
       "          ...,  1.0000+1.1140e-04j,  1.0000+1.0746e-04j,\n",
       "          1.0000+1.0366e-04j],\n",
       "        [-0.4161+9.0930e-01j, -0.3509+9.3641e-01j, -0.2863+9.5814e-01j,\n",
       "          ...,  1.0000+2.2279e-04j,  1.0000+2.1492e-04j,\n",
       "          1.0000+2.0733e-04j],\n",
       "        ...,\n",
       "        [ 0.7877-6.1604e-01j,  0.3603+9.3283e-01j, -0.9966-8.2481e-02j,\n",
       "          ...,  0.9999+1.3924e-02j,  0.9999+1.3432e-02j,\n",
       "          0.9999+1.2958e-02j],\n",
       "        [ 0.9440+3.2999e-01j, -0.5614+8.2756e-01j, -0.5292-8.4850e-01j,\n",
       "          ...,  0.9999+1.4036e-02j,  0.9999+1.3540e-02j,\n",
       "          0.9999+1.3061e-02j],\n",
       "        [ 0.2324+9.7263e-01j, -0.9999+1.0082e-02j,  0.3643-9.3127e-01j,\n",
       "          ...,  0.9999+1.4147e-02j,  0.9999+1.3647e-02j,\n",
       "          0.9999+1.3165e-02j]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precompute_pos_cis(dim=512, max_position = 128, theta=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380358e5-343d-414a-81ea-f42f089823fb",
   "metadata": {},
   "source": [
    "- **polars是什么函数？为什么会出现复数结果？**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cce58ad9-76cc-40a7-9139-581530260a7f",
   "metadata": {},
   "source": [
    "`torch.polar(abs, angle)` 是 PyTorch 中的一个函数，它将给定的模长（`abs`）和角度（`angle`）转换为复数形式。复数的表示方式如下：\n",
    "$$ z = r \\cdot e^{i \\theta} $$\n",
    "其中：\n",
    "- $ z $ 是复数，\n",
    "- $ r $ 是模长，\n",
    "- $ \\theta $是角度，\n",
    "- $ i $ 是虚数单位。\n",
    "\n",
    "`torch.polar(torch.ones_like(freqs), freqs)` 表示生成了复数，其模长为1，角度为 `freqs`。因此，`pos_cis` 包含的每个值都是单位模长的复数，且角度根据 `freqs`（频率）变化。复数在很多场景中用于表示角度旋转、周期性现象（如正弦波和余弦波）和信号处理。在频率编码中，通过使用复数的极坐标形式，便于对旋转的角度进行编码。如果你不想使用复数表示，可以考虑直接使用 `torch.sin()` 和 `torch.cos()` 来对频率进行编码。例如：\n",
    "\n",
    "```python\n",
    "# 直接使用 sin 和 cos 进行位置编码\n",
    "pos_enc_sin = torch.sin(freqs)\n",
    "pos_enc_cos = torch.cos(freqs)\n",
    "\n",
    "# 合并 sin 和 cos 的编码\n",
    "pos_enc = torch.cat([pos_enc_sin, pos_enc_cos], dim=-1)\n",
    "```\n",
    "\n",
    "这样你就可以避免使用复数，并且能够直接获得与传统位置编码相似的正弦和余弦形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2807dd43-e029-4b76-9913-2b6502e2d1e5",
   "metadata": {},
   "source": [
    "- **旋转位置编码仅用于Q和K矩阵**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71221069-0b7b-485d-8b3f-993baf905038",
   "metadata": {},
   "source": [
    "在 LLaMA 中，旋转位置编码（RoPE, Rotary Position Embedding）仅用于 **Q**（Query）和 **K**（Key）矩阵，而不应用于 **V**（Value）矩阵，这有特定的数学和功能性原因，主要与 **自注意力机制** 的工作原理以及相对位置信息的处理方式有关。\n",
    "\n",
    "1. **QK 矩阵与相对位置编码的关联**：\n",
    "\n",
    "在自注意力机制中，注意力权重通过计算 Query 和 Key 的点积来获得，具体公式为：\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) V\n",
    "$$\n",
    "其中 $ Q $ 是查询矩阵，$ K$ 是键矩阵，$ V $ 是值矩阵。\n",
    "\n",
    "通过这种计算，**Query 和 Key 的点积决定了每个位置之间的相对相关性**。如果我们希望通过位置编码让模型意识到输入序列中元素的相对位置，那么只需将旋转位置编码应用于 **Q** 和 **K**，因为它们参与了点积计算，并直接影响注意力得分。\n",
    "\n",
    "- **RoPE 为 QK 计算引入相对位置感知**：  \n",
    "  RoPE 的旋转操作对 Q 和 K 矩阵的特征进行旋转变换，这会改变它们的内积结果，从而为模型注入了相对位置信息。这样，RoPE 能够在 QK 点积时，隐含地捕捉到输入序列中元素之间的相对位置关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306466da-9e80-4dce-bcae-2ad312fc796a",
   "metadata": {},
   "source": [
    "2. **为什么不对 V（Value）矩阵应用 RoPE**：\n",
    "\n",
    "- **V 矩阵的作用**：  \n",
    "  Value 矩阵 $ V $ 不参与注意力权重的计算，而是用于对注意力权重加权后的特征进行值传递。换句话说，**V 矩阵携带的是特征信息**，而不是决定哪些特征与哪些位置相关联。\n",
    "\n",
    "- **RoPE 的作用与相对位置无关**：  \n",
    "  因为 RoPE 的主要作用是为 Q 和 K 的点积引入相对位置感知，而 V 矩阵只是根据计算出的注意力权重进行加权，没有必要加入位置信息。如果对 V 矩阵也应用 RoPE，反而会破坏其携带的原始特征信息，不利于最终的模型表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31723f1-7737-4685-8ee1-745094c2a21b",
   "metadata": {},
   "source": [
    "3. **RoPE 提供的相对位置感知**：\n",
    "自注意力机制的重点在于位置之间的相对关系，而不是每个位置的绝对位置。RoPE 正是通过对 Q 和 K 矩阵进行旋转，将相对位置信息引入点积结果中。由于 V 矩阵不参与计算相似性，使用 RoPE 对其进行变换没有实际意义，反而会导致不必要的复杂性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3d3ef7-20c7-476a-92cb-c1e65855c946",
   "metadata": {},
   "source": [
    "4. **计算复杂度和效率的考虑**：\n",
    "自注意力机制的计算量主要集中在 QK 点积和注意力权重的计算上。如果对 V 矩阵也应用 RoPE，会增加额外的计算复杂度和参数量，而这些额外的操作并不会对模型的性能带来明显改善。因此，RoPE 只应用于 Q 和 K，有助于保持计算效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "776837ee-6d38-42cc-a089-d8ba2c85d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将频率用于q、k矩阵\n",
    "def apply_rotary_emb(xq, xk, pos_cis):\n",
    "    def unite_shape(pos_cis, x):\n",
    "        ndim = x.ndim\n",
    "        assert 0 <= 1 < ndim\n",
    "        print(pos_cis.shape)\n",
    "        print(x.shape[1])\n",
    "        print(x.shape[-1])\n",
    "        assert pos_cis.shape == (x.shape[1], x.shape[-1])\n",
    "        shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "        return pos_cis.view(*shape)\n",
    "\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    pos_cis = unite_shape(pos_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * pos_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * pos_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c9165-a424-4237-b6bb-0963fde25443",
   "metadata": {},
   "source": [
    "这个函数 `apply_rotary_emb` 用于在计算自注意力机制时将旋转嵌入（rotary embeddings）应用到查询（`q`）和键（`k`）矩阵上。这种旋转嵌入是通过将频率（`pos_cis`）与 `q` 和 `k` 矩阵相结合来实现的，目的是提升模型对位置信息的编码能力。以下是逐行注释：\n",
    "\n",
    "```python\n",
    "# 将频率（位置编码）应用于查询矩阵 q 和键矩阵 k\n",
    "def apply_rotary_emb(xq, xk, pos_cis):\n",
    "    # 内部函数：用于调整 pos_cis（位置编码）的形状，使其与输入张量 x 的形状匹配\n",
    "    def unite_shape(pos_cis, x):\n",
    "        # 注意这里输入的x是已经转变为复数的Q和K矩阵\n",
    "        # 复数Q、K矩阵的维度与实数Q、K矩阵的维度有区别\n",
    "        # 例如，当实数Q矩阵的结构为 (10,128,512) 时\n",
    "        # 复数Q矩阵的结构为(10,128,256,2)，其中后两位代表复数的实部和虚部\n",
    "        # 此时如果对Q矩阵取最后一维索引，会得到最后一个实部，也就是256\n",
    "        # 获取输入张量的维度数量\n",
    "        ndim = x.ndim\n",
    "        # 确保输入张量的维度数是有效的\n",
    "        assert 0 <= 1 < ndim\n",
    "        # 确保 pos_cis 的形状与输入 x 的形状中的seq_len, d_model维度匹配\n",
    "        assert pos_cis.shape == (x.shape[1], x.shape[-1])\n",
    "        # 构造新的形状，除了第二维度和最后一维度之外，其他维度都设置为 1\n",
    "        # 这是为了广播 pos_cis 以匹配输入 x 的形状\n",
    "        shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "        # 调整 pos_cis 的形状为新的 shape\n",
    "        return pos_cis.view(*shape)\n",
    "\n",
    "    # 将查询张量 xq 的最后一个维度视为复数的一部分，形状变为 (*xq.shape[:-1], -1, 2)\n",
    "    # 这意味着将最后一维度按 2 拆分，转换为复数表示（因为一个复数由实部和虚部组成）\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "\n",
    "    # 对键张量 xk 做同样的处理，将其转换为复数形式\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "\n",
    "    # 调整 pos_cis 的形状，使其与查询矩阵 xq_ 的形状匹配\n",
    "    pos_cis = unite_shape(pos_cis, xq_)\n",
    "\n",
    "    # 将旋转嵌入应用到查询矩阵，复数乘法会影响幅度和相位\n",
    "    # 然后将复数结果转换回实数形式并将其展平（恢复到原来的维度结构）\n",
    "    xq_out = torch.view_as_real(xq_ * pos_cis).flatten(3)\n",
    "\n",
    "    # 对键矩阵做同样的操作，应用旋转嵌入\n",
    "    xk_out = torch.view_as_real(xk_ * pos_cis).flatten(3)\n",
    "\n",
    "    # 返回处理后的查询矩阵和键矩阵，且类型与输入张量相同\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "```\n",
    "\n",
    "- 总结：\n",
    "1. **输入参数：**\n",
    "   - `xq`: 查询矩阵，通常来自自注意力机制中的查询。\n",
    "   - `xk`: 键矩阵，通常来自自注意力机制中的键。\n",
    "   - `pos_cis`: 位置编码信息，通常是通过旋转嵌入（rotary embeddings）生成的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612cce1a-1300-472f-aa02-f8eeccbbf58f",
   "metadata": {},
   "source": [
    "2. **关键步骤：**\n",
    "   - **`unite_shape`**: 调整 `pos_cis` 的形状，使其可以通过广播机制与 `xq` 和 `xk` 相乘。\n",
    "   - **`torch.view_as_complex`**: 将查询矩阵 `xq` 和键矩阵 `xk` 的最后一维转换为复数表示（通过将最后一维分成实部和虚部）。\n",
    "   - **复数乘法**：将复数表示的 `xq` 和 `xk` 分别与位置编码 `pos_cis` 进行复数乘法。复数乘法会同时影响向量的幅度和相位（实现位置编码的效果）。\n",
    "   - **`torch.view_as_real`**: 将复数乘法的结果转换回实数形式，并将结果展平为原来的形状。\n",
    "   - **`flatten(3)`**: 展平最后两个维度，使得张量形状回归到与输入相同的结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17250b2-5db0-47bf-a25c-d6e50984a008",
   "metadata": {},
   "source": [
    "3. **返回：**\n",
    "   - 返回应用了旋转嵌入的查询矩阵和键矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba7d24-3bd7-4e3f-8435-08073741b263",
   "metadata": {},
   "source": [
    "- **为什么不直接使用正余弦位置编码？旋转位置编码有什么好处？**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdde1951-6e31-4cac-8d60-6068d8d899cc",
   "metadata": {},
   "source": [
    "1. **相对位置信息的编码**：与传统的正余弦编码主要侧重于绝对位置不同，RoPE能够自然地融入**相对位置信息**。这使得模型可以更好地理解序列中各个词之间的相对关系，对于那些词与词之间距离影响其关联性的任务尤为重要。RoPE通过在注意力机制中旋转查询和键向量，并且随着词之间距离的增加，它们的内积逐渐减弱，这有助于更好地模拟自然语言中远距离词语关联度降低的现象。\n",
    "\n",
    "**正余弦位置编码**（Positional Encoding）的确利用了周期性函数（如正弦和余弦）来表示位置信息，其基本原理是通过不同频率的正弦和余弦函数来为每个位置分配一个独特的向量。这个向量的不同维度对不同频率进行编码，从而使得每个位置都有一个唯一的编码值，因此正余弦编码虽然是周期性的，但**它本质上是绝对位置编码**，因为它依赖于位置的绝对值。也就是说，它为每个特定的位置生成一个固定的编码，而不考虑其他位置。例如，序列中的第5个词和第10个词，即使它们距离很近或很远，它们的编码值只取决于它们在序列中的具体位置（即位置5和位置10），而不是它们之间的相对距离。相比之下，旋转位置编码（RoPE）将关注点放在相对位置上。它通过在自注意力机制中旋转查询和键向量，使得随着两个词之间距离的增加，它们的点积逐渐衰减，从而在模型中直接融入相对位置信息。这样，旋转位置编码可以更好地处理序列中相对距离的变化，而正余弦编码则更专注于词语的绝对位置。\n",
    "\n",
    "2. **对序列长度的适应性**：旋转位置编码在序列长度上具有很高的灵活性。传统的正余弦编码在处理超出训练时序列长度的情况下，性能往往会下降，而RoPE可以轻松扩展到不同的序列长度，且性能下降较小。这是因为旋转过程不依赖于固定的长度，能够在不同长度的序列中保持有效性。\n",
    "\n",
    "3. **高效且乘法式的编码方式**：RoPE使用乘法方法，而不是传统位置编码中的加法方法。这种方式可以在为模型提供位置上下文的同时，保留更多原始词嵌入的信息。此外，旋转的性质在结合线性注意力机制时能保证稳定性和计算效率，使RoPE在某些大规模模型中成为一种更为高效的选择。\n",
    "\n",
    "总的来说，RoPE的优势在于其对相对位置的编码能力以及对不同长度序列的适应性，使其成为在LLaMA等基于Transformer架构中的一种强大且灵活的替代方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab58c9-7241-4cb6-a5fb-5a49dd414949",
   "metadata": {},
   "source": [
    "## 4. LLaMA中的注意力机制与kv缓存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a70e10-c5fe-4760-b14f-46af96caa579",
   "metadata": {},
   "source": [
    "**KV缓存（Key-Value Cache）**机制在Transformer模型的自回归生成任务中（如文本生成）是一种重要的加速技术，尤其是在处理长序列时。它能够减少重复计算，从而加速推理过程。这种机制主要应用于**解码器**架构，常见于GPT系列模型等自回归模型。在自回归生成任务中，模型逐步生成序列中的每个token。例如，在文本生成中，每一步生成一个新的token，然后将这个token与之前的所有tokens一起重新输入模型，预测下一个token。对于每一步的生成，模型会重新计算所有tokens的注意力（self-attention），包括所有历史tokens（即已经生成的tokens）和当前生成的token。\n",
    "\n",
    "在Transformer的每一层中，注意力机制会基于输入生成**查询（Query）**、**键（Key）**和**值（Value）**。计算公式如下：\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) V\n",
    "$$\n",
    "\n",
    "- `Query` 表示当前token的信息，它用于寻找与其他tokens相关的内容。\n",
    "- `Key` 和 `Value` 分别代表历史tokens的信息，它们在每个生成步骤中被重新计算。\n",
    "\n",
    "这种重新计算会导致计算量成倍增加。例如，如果生成了100个token，每一步都会重新计算前面99个token和当前token的注意力，这样的重复计算是非常耗时的。**KV缓存机制**的核心思想是避免重复计算注意力层（self-attention）中的键（Key）和值（Value）。KV缓存通过将生成过程中每个token的Key和Value保存在缓存中，只在第一次生成时计算一次Key和Value。在生成后续token时，模型只需要计算新token的Query，而可以直接使用缓存中已经存储的Key和Value，避免了对历史tokens的重复计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41076e4-0d84-4e46-a445-5dadd0e7c30b",
   "metadata": {},
   "source": [
    "- **工作原理**\n",
    "\n",
    "以下是KV缓存机制的详细工作原理。注意，**KV缓存大部分时候适用于推理，因此这个流程大部分时候是自回归的**。\n",
    "\n",
    "1. **初始化**：\n",
    "   - 当生成开始时，模型计算输入序列的Key和Value，并将这些计算结果缓存起来，保存在内存中。\n",
    "     \n",
    "   - **大部分时候，每个注意力层都会有一对Key-Value缓存，这个缓存是在自回归的每次循环中共用。然而，有时我们也可以在多头注意力机制中、只保留一个头或两个头上的KV值，并共享给所有的头使用**。其中，每次循环中的kv缓存，是推理中常见的用法。多头共享kv的缓存，可以被用于训练和推理两个流程，但可能伤害训练的结果。\n",
    "     \n",
    "   - 这些缓存的Key和Value会存储到KV缓存中，并作为后续生成步骤中的参考。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4508c3f-d13b-4c9d-9b0e-6bf3d8569dee",
   "metadata": {},
   "source": [
    "2. **生成过程中**：\n",
    "   - 当生成下一个token时，模型不需要重新计算前面已经生成的token的Key和Value。它会直接使用之前缓存的Key和Value。\n",
    "   - 只需要计算当前token的Query，并将它与已经缓存的Key进行点积计算，得出注意力分数。\n",
    "   - 这些注意力分数会结合缓存的Value来计算当前token的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc375df-a0fc-477b-8315-e32eba6ef4da",
   "metadata": {},
   "source": [
    "3. **更新缓存**：\n",
    "   - 对于每一个生成步骤，模型还会将当前生成的token的Key和Value加入缓存，确保缓存中的Key和Value始终保持更新，包含所有已经生成的tokens。\n",
    "   - 缓存的大小会逐渐增加，最终会包含所有生成序列的Key和Value。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238971cc-1ef1-42ca-ab67-fad726b88a17",
   "metadata": {},
   "source": [
    "4. **加速效果**：\n",
    "   - 由于每个生成步骤只需要计算当前token的Query，而不需要重新计算整个序列的Key和Value，这大大减少了计算量。\n",
    "   - 随着序列长度增加，缓存的使用能够显著减少时间复杂度，使生成过程更快。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ec304-2a73-47f8-a73f-7eb351306b4c",
   "metadata": {},
   "source": [
    "- **实现代码**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a8904a8-4172-4324-a2cc-f6306c3227bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    \"\"\"torch.repeat_interleave(x, dim=2, repeats=n_rep)\"\"\"\n",
    "    bs, slen, n_kv_heads, head_dim = x.shape\n",
    "    if n_rep == 1:\n",
    "        return x\n",
    "    return (\n",
    "        x[:, :, :, None, :]\n",
    "        .expand(bs, slen, n_kv_heads, n_rep, head_dim)\n",
    "        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639106ec-c7f9-42cf-bc51-e3881dd0a15e",
   "metadata": {},
   "source": [
    "代码解读——"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d21d6db-799d-4856-b704-583dafde0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    \"\"\"torch.repeat_interleave(x, dim=2, repeats=n_rep)\"\"\"\n",
    "    # 定义函数 repeat_kv，接受两个参数：张量 x 和重复次数 n_rep\n",
    "    # x 是一个形状为 (bs, slen, n_kv_heads, head_dim) 的张量，分别代表：\n",
    "    # bs: 批次大小 (batch size)\n",
    "    # slen: 序列长度 (sequence length)\n",
    "    # n_kv_heads: KV 头的数量 (number of key-value heads)\n",
    "    # head_dim: 每个头的维度大小 (dimension size of each head)\n",
    "    # n_rep: 重复次数\n",
    "\n",
    "    # 获取张量的形状 (bs: 批次大小, slen: 序列长度, n_kv_heads: KV 头的数量, head_dim: 每个头的维度)\n",
    "    bs, slen, n_kv_heads, head_dim = x.shape\n",
    "\n",
    "    # 如果 n_rep 为 1，表示不需要重复，直接返回原始张量\n",
    "    if n_rep == 1:\n",
    "        return x\n",
    "\n",
    "    # 执行以下操作以重复 KV 头：\n",
    "    # 1. 在第 4 维度 (即 None) 上扩展 x，使其形状为 (bs, slen, n_kv_heads, 1, head_dim)\n",
    "    # 2. 使用 expand 函数将第 4 维度扩展为 n_rep，得到形状 (bs, slen, n_kv_heads, n_rep, head_dim)\n",
    "    # 3. 最后通过 reshape 将形状重新调整为 (bs, slen, n_kv_heads * n_rep, head_dim)\n",
    "    # 这会将每个 KV 头重复 n_rep 次\n",
    "    return (\n",
    "        x[:, :, :, None, :]                       # 扩展张量，在 n_kv_heads 后增加一个维度\n",
    "        .expand(bs, slen, n_kv_heads, n_rep, head_dim)  # 扩展 n_rep 次\n",
    "        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)  # 调整形状为新的维度\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29d6cac-28a1-4e52-a3d6-9a370504a9b6",
   "metadata": {},
   "source": [
    "<font color=\"red\">**根据我们的解读，不难看出，这一段代码是允许多头注意力机制的多个头共享kv缓存的代码。如果要让每个头都拥有自己独特的k和v，只在推理过程中每个循环中进行缓存，那只要让n_rep=1即可。**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a3b42-0d4f-4c58-88da-6575401f5832",
   "metadata": {},
   "source": [
    "- KV缓存的优点\n",
    "\n",
    "1. **提高生成速度**：由于避免了对已经生成token的重复计算，KV缓存机制可以显著减少生成时间，特别是在长序列生成任务中。\n",
    "   \n",
    "2. **节省计算资源**：缓存Key和Value后，每一步生成仅需计算当前token的Query，而Key和Value可以从缓存中提取，从而大幅减少每一步的计算量。\n",
    "\n",
    "3. **降低复杂度**：使用缓存后，生成过程中的注意力机制从 O(n²) 降为 O(n)，其中 n 是序列长度。对于长序列生成任务，这种加速效果尤为显著。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3af849-75d0-4eb5-859f-9f3285dfb7ec",
   "metadata": {},
   "source": [
    "- KV缓存与DeepSpeed和Hugging Face的结合\n",
    "\n",
    "> - **DeepSpeed**：KV缓存在DeepSpeed等加速框架中发挥更大作用，DeepSpeed可以进一步优化KV缓存的使用，利用其高效的并行和内存管理机制，进一步提升生成过程中的性能。<br><br>\n",
    "> - **Hugging Face**：Hugging Face的模型可以直接支持KV缓存，特别是其`generate`函数可以通过指定`kv_cache=True`来启用KV缓存，优化推理和生成过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4815b8d8-a56a-41a7-ba71-1b971ed1a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在运行Attention之前，你首先需要设置好配置文件LMConfig\n",
    "#我们所有的参数都从LMConfig里面导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "fb2af69d-5820-4600-b93c-9b34f890f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: LMConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        # 先确定n_kv_heads的值，如果设置了单独的n_kv_heads，就执行多头共享机制\n",
    "        # 如果没设置kv_heads，就意味着全部的头都要执行kv缓存，此时n_kv_heads = n_heads\n",
    "        self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads\n",
    "\n",
    "        # 检验，n_heads能否被n_kv_heads除尽\n",
    "        assert args.n_heads % self.n_kv_heads == 0\n",
    "\n",
    "        # 设置头数、kv缓存头数和重复次数\n",
    "        self.n_local_heads = args.n_heads\n",
    "        self.n_local_kv_heads = self.n_kv_heads\n",
    "        self.n_rep = self.n_local_heads // self.n_local_kv_heads\n",
    "\n",
    "        # 设置每个头上的特征维度\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        # 设置权重层，当 x 的结构为 (seq_len, d_model)时\n",
    "        # 常规的Q、K、V矩阵的结构应该与 X 一致，也是 (seq_len, d_model)\n",
    "        # 因此常规的 w 应该是 (d_model,d_model)结构\n",
    "        # 在多头注意力中，w 应该是 (d_model, d_model/n_heads)\n",
    "        # 在具有kv缓存的情况下，我们是对所有头上的注意力并行计算\n",
    "        # 因此Q的权重应该是(d_model, d_model)\n",
    "        # K和V的权重应该是(d_model, d_model/n_heads * n_kv_heads)\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)\n",
    "\n",
    "        # 输出层上的O的权重不受影响，是(d_model, d_model)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "        # 设置kv缓存初始值\n",
    "        self.k_cache, self.v_cache = None, None\n",
    "\n",
    "        # 设置注意力和残差连接上的dropout层和dropout比例\n",
    "        self.attn_dropout = nn.Dropout(args.dropout)\n",
    "        self.resid_dropout = nn.Dropout(args.dropout)\n",
    "        self.dropout = args.dropout\n",
    "\n",
    "        # flash attention\n",
    "        # print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
    "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention') and args.flash_attn\n",
    "\n",
    "        # 设置decoder专用前瞻掩码\n",
    "        # 注意，前瞻掩码是用于QK.T矩阵的\n",
    "        mask = torch.full((1, 1, args.max_seq_len, args.max_seq_len), float(\"-inf\"))\n",
    "        mask = torch.triu(mask, diagonal=1)\n",
    "\n",
    "        # buffer用于保存神经网络中除了权重之外、需要被保存的静态数据们\n",
    "        # 比如掩码矩阵、比如位置编码中的频率等等编码表\n",
    "        # \"mask\"我们指定的buffer名称，我们可以通过self.mask来调出掩码矩阵\n",
    "        self.register_buffer(\"mask\", mask, persistent=False)\n",
    "\n",
    "    # 设置旋转位置编码中的频率计算\n",
    "    def _precompute_pos_cis(self, dim: int, max_position = 10000, theta: float = 10000.0):\n",
    "        freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "        m = torch.arange(max_position, device=freqs.device)\n",
    "        freqs = torch.outer(m, freqs).float()\n",
    "        pos_cis = torch.polar(torch.ones_like(freqs), freqs)\n",
    "        return pos_cis\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, kv_cache=False):\n",
    "\n",
    "        # 作为注意力机制，被输入的x就是原始数据x\n",
    "        # 结构为 (bs, seq_len, d_model)\n",
    "        bsz, seqlen, _ = x.shape\n",
    "\n",
    "        # 无论是否执行KV缓存，Q的求解是不变的\n",
    "        xq = self.wq(x)\n",
    "\n",
    "        # 如果是训练模式下，K和V照常求解\n",
    "        if self.train():\n",
    "            # 将x输入线性层、转换为初始的K和V\n",
    "            # 但是只需要n_kv_heads个头的部分\n",
    "            xk, xv = self.wk(x), self.wv(x)\n",
    "\n",
    "        # 如果是推理模式，且kv_cache设置是打开的\n",
    "        # 那要判断现在是否是初次预测\n",
    "        if kv_cache and self.eval():\n",
    "            # kv缓存是否还是None？已经存在了吗？\n",
    "            if all(cache is not None for cache in (self.k_cache, self.v_cache)):\n",
    "                # 如果不是None，说明不是初次预测了，此时需要的是缓存更新\n",
    "                xk_new_token = self.wk(x[:,-1,:]).unsqueeze(1)\n",
    "                xv_new_token = self.wv(x[:,-1,:]).unsqueeze(1)\n",
    "                xk = torch.cat((self.k_cache, xk_new_token), dim=1)\n",
    "                xv = torch.cat((self.v_cache, xv_new_token), dim=1)\n",
    "            else:\n",
    "                # 如果k和v缓存中有一个为None，说明是初次预测\n",
    "                xk, xv = self.wk(x), self.wv(x)\n",
    "            #生成xk和xv后，把结果保存到缓存中\n",
    "            self.k_cache, self.v_cache = xk, xv\n",
    "\n",
    "        # 为了更省内存，我们要将数据结构重新整理后适应位置编码的结构\n",
    "        # 可以将该流程命名为“多头旋转位置编码”\n",
    "        xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)\n",
    "\n",
    "        # 在Q和K上执行旋转位置编码\n",
    "        pos_cis = self._precompute_pos_cis(self.head_dim, seqlen)\n",
    "        xq, xk = apply_rotary_emb(xq, xk, pos_cis)\n",
    "\n",
    "        # 将k矩阵和v矩阵进行重复\n",
    "        xk = repeat_kv(xk, self.n_rep)  # (bs, seqlen, n_local_heads, head_dim)\n",
    "        xv = repeat_kv(xv, self.n_rep)  # (bs, seqlen, n_local_heads, head_dim)\n",
    "\n",
    "        # 矩阵乘法计算注意力分数时，要将n_heads作为第二维度\n",
    "        # 因为实际要进行乘法的应该时 (seqlen, head_dim) 这样的二维表\n",
    "        # transpose交换维度，结构变为(bs, n_local_heads, seqlen, head_dim)\n",
    "        xq = xq.transpose(1, 2)\n",
    "        xk = xk.transpose(1, 2)\n",
    "        xv = xv.transpose(1, 2)\n",
    "\n",
    "        # 如果使用flash attention的话\n",
    "        # 就调用nn.functional下面的点乘注意力计算方法\n",
    "        if self.flash and seqlen != 1:\n",
    "            output = torch.nn.functional.scaled_dot_product_attention(xq, xk, xv\n",
    "                                                                      , attn_mask=None #这里是padding掩码\n",
    "                                                                      , dropout_p=self.dropout if self.training else 0.0\n",
    "                                                                      , is_causal=True #这里是自动化的前瞻掩码\n",
    "                                                                     )\n",
    "        else:\n",
    "            # 不使用flash attention，就自己计算\n",
    "            # 这里的transpose是对最后两个维度的转置\n",
    "            scores = torch.matmul(xq, xk.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "            \n",
    "            # 在注意力分数上放上掩码\n",
    "            # 如果有kv缓存的话，现在我们的kv矩阵可能会比掩码矩阵要大了\n",
    "            # 获取缓存的长度\n",
    "            cache_len = self.k_cache.shape[1] if self.k_cache is not None else 0\n",
    "            total_len = cache_len + 1  # 当前总长度，等于历史缓存长度 + 当前序列长度\n",
    "\n",
    "            # 检查是否需要扩展掩码矩阵\n",
    "            if total_len > self.mask.shape[-1]:\n",
    "                # 动态生成新的掩码，大小为 (seq_len + cache_len, seq_len + cache_len)\n",
    "                new_mask = torch.full((1, 1, total_len, total_len), float(\"-inf\")).to(x.device)\n",
    "                new_mask = torch.triu(new_mask, diagonal=1)  # 生成前瞻掩码\n",
    "                self.mask = new_mask  # 更新掩码矩阵\n",
    "            \n",
    "            scores = scores + self.mask[:, :, :seqlen, :seqlen]\n",
    "                \n",
    "            # 对最后一个维度求解softmax\n",
    "            scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "            scores = self.attn_dropout(scores)\n",
    "            output = torch.matmul(scores, xv)  # (bs, n_local_heads, seqlen, head_dim)\n",
    "\n",
    "        # 最后再将结构转回来，并且将n_heads中的所有信息合并\n",
    "        # contiguous() 用于确保张量在内存中的存储是连续的\n",
    "        # 特别是在经过某些操作（如 transpose）后，这对后续的 view() 等操作至关重要，以避免错误\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        # 注意力机制的输出\n",
    "        output = self.wo(output)\n",
    "        output = self.resid_dropout(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f15ac6-1091-42ab-b600-662b64f3a5db",
   "metadata": {},
   "source": [
    "- 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e9f5b12c-0cec-40f0-a43d-e9a5fc8911f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假定的配置类\n",
    "class LMConfig_:\n",
    "    def __init__(self, n_heads=8, n_kv_heads=2, dim=512, max_seq_len=10000, dropout=0.1, flash_attn=False):\n",
    "        self.n_heads = n_heads  # 注意力头的数量\n",
    "        self.n_kv_heads = n_kv_heads  # KV共享头的数量\n",
    "        self.dim = dim  # 模型的维度\n",
    "        self.max_seq_len = max_seq_len  # 最大序列长度\n",
    "        self.dropout = dropout  # dropout比例\n",
    "        self.flash_attn = flash_attn  # 是否使用flash attention\n",
    "\n",
    "# Attention类的测试实例化\n",
    "args_ = LMConfig_()\n",
    "\n",
    "# 重复kv\n",
    "def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    \"\"\"torch.repeat_interleave(x, dim=2, repeats=n_rep)\"\"\"\n",
    "    bs, slen, n_kv_heads, head_dim = x.shape\n",
    "    if n_rep == 1:\n",
    "        return x\n",
    "    return (\n",
    "        x[:, :, :, None, :]\n",
    "        .expand(bs, slen, n_kv_heads, n_rep, head_dim)\n",
    "        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)\n",
    "    )\n",
    "\n",
    "#将频率用于q、k矩阵\n",
    "def apply_rotary_emb(xq, xk, pos_cis):\n",
    "    def unite_shape(pos_cis, x):\n",
    "        ndim = x.ndim\n",
    "        assert 0 <= 1 < ndim\n",
    "        assert pos_cis.shape == (x.shape[1], x.shape[-1])\n",
    "        shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "        return pos_cis.view(*shape)\n",
    "\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    pos_cis = unite_shape(pos_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * pos_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * pos_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "59be57cf-34f1-4526-8bc3-d5d91fc82c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建假设输入\n",
    "x = torch.randn(2, 10, 512)  # (batch_size=2, seq_len=10, dim=512)\n",
    "pos_cis = precompute_pos_cis(dim=64, max_position = 10, theta=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f4ba42ae-f7ce-41f5-aa30-6d077f0e4bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 512])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建Attention实例\n",
    "attention = Attention(args_)\n",
    "\n",
    "# 前向传播\n",
    "output = attention(x,kv_cache=True)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c400a7-d46d-44fa-8a6a-0d8532c034ce",
   "metadata": {},
   "source": [
    "- **验证是否开启kv缓存会带来的运算速度变化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fe1f1a56-b318-489a-b738-c0321207a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 定义计时函数\n",
    "def measure_inference_time(attention, x, kv_cache):\n",
    "    start_time = time.time()\n",
    "    output = attention(x, kv_cache=kv_cache)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2cf83370-376f-4cec-9fff-324c8f3a24b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理时间（关闭kv_cache）: 0.006324 秒\n"
     ]
    }
   ],
   "source": [
    "# 创建假设输入\n",
    "x = torch.randn(2, 100, 512)  # (batch_size=2, seq_len=100, dim=512)\n",
    "head_dim = int(512/8)\n",
    "\n",
    "# 创建Attention实例\n",
    "attention = Attention(args_)\n",
    "\n",
    "# 测试关闭kv_cache的推理时间\n",
    "time_without_cache = measure_inference_time(attention, x, kv_cache=False)\n",
    "print(f\"推理时间（关闭kv_cache）: {time_without_cache:.6f} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7e91b02f-3f39-4f52-9331-9386a7bc63f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理时间（开启kv_cache）: 78.550040 秒\n"
     ]
    }
   ],
   "source": [
    "# 模拟逐步生成的推理输入（关闭kv_cache）\n",
    "x = torch.randn(2, 200, 512)\n",
    "x_new_token = torch.randn(2, 1, 512)  # 模拟单个新生成的token\n",
    "attention.k_cache = None  # 清空KV缓存\n",
    "head_dim = int(512/8)\n",
    "\n",
    "# 运行并计时\n",
    "time_with_cache = 0.0\n",
    "for i in range(1000):  # 模拟生成1000个token的过程\n",
    "    x = torch.cat((x, x_new_token), dim=1)\n",
    "    time_with_cache += measure_inference_time(attention, x, kv_cache=False)\n",
    "\n",
    "print(f\"推理时间（开启kv_cache）: {time_with_cache:.6f} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a9134241-0315-4751-93c4-87524805cac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理时间（开启kv_cache）: 58.885653 秒\n"
     ]
    }
   ],
   "source": [
    "# 模拟逐步生成的推理输入（开启kv_cache）\n",
    "x = torch.randn(2, 200, 512)\n",
    "x_new_token = torch.randn(2, 1, 512)  # 模拟单个新生成的token\n",
    "attention.k_cache = None  # 清空KV缓存\n",
    "head_dim = int(512/8)\n",
    "\n",
    "# 运行并计时\n",
    "time_with_cache = 0.0\n",
    "for i in range(1000):  # 模拟生成100个token的过程\n",
    "    x = torch.cat((x, x_new_token), dim=1)\n",
    "    time_with_cache += measure_inference_time(attention, x, kv_cache=True)\n",
    "\n",
    "print(f\"推理时间（开启kv_cache）: {time_with_cache:.6f} 秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66d6981-74a3-47e7-af77-ec91a3fac6ed",
   "metadata": {},
   "source": [
    "## 5. 门控前馈神经网络FFN with SwiGLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea1f833-f4d6-49c8-a1d9-9b1da7e2c622",
   "metadata": {},
   "source": [
    "与常见的前馈神经网络相比，Llama中的前馈神经网络有一些独特的设计。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e79024d-b295-4cc4-881a-01ae0e8748a1",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2024LLM/15.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "091e740f-50a8-434b-97c5-51426f20bc78",
   "metadata": {},
   "source": [
    "> **典型前馈网络**：\n",
    "$$\n",
    "  \\text{Output} = \\text{Linear2}(\\text{Activation}(\\text{Linear1}(x)))\n",
    "$$\n",
    "  它通过一个线性层（`Linear1`），一个非线性激活函数（如ReLU或GELU），然后通过另一个线性层（`Linear2`）。\n",
    "\n",
    "> **llama中的前馈神经网络**\n",
    "$$\n",
    "\\text{Output} = \\text{Linear2}\n",
    "\\left( \\textcolor{red}{\\text{Activation}}\\left( \\textcolor{green}{\\text{Linear1}}(x) \\right) \n",
    "\\odot \\textcolor{gold}{\\text{Linear3}}(x) \\right)\n",
    "$$\n",
    "  它通过两个线性层（`Linear1`和`Linear3`），从`Linear1`输出的结果经过silu激活函数后，与`Linear3`输出的结果进行逐元素乘法，然后通过另一个线性层（`Linear2`）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f2be7-0329-42a3-9f45-0bf3b76cac97",
   "metadata": {},
   "source": [
    "为什么llama要做这样的修改呢？为了要了解这个前馈网络的机制，我们先要了解一下SwiGLU激活函数。\n",
    "\n",
    "- **SwiGLU（Switch-Gated Linear Unit）门控线性单元激活函数**\n",
    "\n",
    "**SwiGLU** 是一种新型的激活函数，由 **Shazeer (2020)** 在论文 *“Gated Linear Units for Efficient and Scalable Deep Learning”* 中提出。它被用在 **深度学习模型的前馈神经网络（FFN）层**中，如 **LLaMA**、**GPT-3** 和其他大型 Transformer 模型中。SwiGLU 的设计核心是基于**门控机制（gating mechanism）**，它通过引入两个线性路径的输出，并结合逐元素乘法，实现了对信息的动态控制。这种门控结构类似于在 LSTM 和 GRU 等门控循环网络中的思想，但它被应用在 Transformer 的前馈网络（FFN）层中，用于增强网络的非线性表达能力和训练效率。\n",
    "\n",
    "SwiGLU 激活函数的基本形式如下：\n",
    "\n",
    "$$\n",
    "\\text{SwiGLU}(x) = \\textcolor{red}{\\text{GELU}}\\left( \\textcolor{green}{W_1^a} \\cdot x \\right) \n",
    "\\odot \\textcolor{gold}{W_1^b} \\cdot x\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $W_1^a$ 和 $W_1^b$ 是线性变换（全连接层）。\n",
    "- $\\odot$ 表示 **逐元素乘法**（element-wise multiplication）。\n",
    "- **GELU**（Gaussian Error Linear Unit）是一个非线性激活函数，它与ReLU激活函数类似，但它比 ReLU 更平滑，适用于深度模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e4c870-3189-4cfe-9741-19f9b34fb436",
   "metadata": {},
   "source": [
    "| **特性**           | **ReLU**                        | **GELU**                      | **SwiGLU with GELU**                    |\n",
    "|--------------------|---------------------------------|--------------------------------|--------------------------------|\n",
    "| **表达能力**       | 线性激活，易丢失负值信息         | 平滑激活，但无门控机制         | 动态门控，表达能力最强         |\n",
    "| **梯度流动**       | 负值梯度为 0，可能导致死神经元   | 平滑梯度流动                   | 更平滑的梯度流动，训练更稳定   |\n",
    "| **训练效率**       | 计算简单，但可能不稳定           | 计算稍复杂，但效果更好         | 高效计算，适合大规模模型       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69990dc5-c5e9-4745-b275-1b464a899d43",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义 ReLU 激活函数及其梯度\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "# 定义 GELU 激活函数及其梯度\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))\n",
    "\n",
    "def gelu_derivative(x):\n",
    "    tanh_term = np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3))\n",
    "    sech2_term = 1 - tanh_term ** 2  # tanh 导数\n",
    "    return 0.5 * (1 + tanh_term + np.sqrt(2 / np.pi) * x * (1 + 3 * 0.044715 * x**2) * sech2_term)\n",
    "\n",
    "# 定义 SwiGLU 激活函数及其梯度\n",
    "def swiglu(x, W1a=1.0, W1b=1.0):\n",
    "    return gelu(W1a * x) * (W1b * x)\n",
    "\n",
    "def swiglu_derivative(x, W1a=1.0, W1b=1.0):\n",
    "    gelu_grad = gelu_derivative(W1a * x) * W1a\n",
    "    return gelu_grad * (W1b * x) + gelu(W1a * x) * W1b\n",
    "\n",
    "# 创建输入数据\n",
    "x = np.linspace(-6, 6, 400)\n",
    "\n",
    "# 计算所有函数及其梯度\n",
    "y_relu, y_relu_grad = relu(x), relu_derivative(x)\n",
    "y_gelu, y_gelu_grad = gelu(x), gelu_derivative(x)\n",
    "y_swiglu, y_swiglu_grad = swiglu(x), swiglu_derivative(x)\n",
    "\n",
    "# 绘制 3x2 图像布局\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 15))\n",
    "\n",
    "# ReLU 激活函数和梯度\n",
    "axes[0, 0].plot(x, y_relu, color='b', label='ReLU')\n",
    "axes[0, 0].set_title('ReLU Activation',size=20)\n",
    "axes[0, 0].grid(True)\n",
    "axes[0, 1].plot(x, y_relu_grad, color='r', label='ReLU Gradient')\n",
    "axes[0, 1].set_title('ReLU Gradient',size=20)\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# GELU 激活函数和梯度\n",
    "axes[1, 0].plot(x, y_gelu, color='b', label='GELU')\n",
    "axes[1, 0].set_title('GELU Activation',size=20)\n",
    "axes[1, 0].grid(True)\n",
    "axes[1, 1].plot(x, y_gelu_grad, color='r', label='GELU Gradient')\n",
    "axes[1, 1].set_title('GELU Gradient',size=20)\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "# SwiGLU 激活函数和梯度\n",
    "axes[2, 0].plot(x, y_swiglu, color='b', label='SwiGLU')\n",
    "axes[2, 0].set_title('SwiGLU Activation',size=20)\n",
    "axes[2, 0].grid(True)\n",
    "axes[2, 1].plot(x, y_swiglu_grad, color='r', label='SwiGLU Gradient')\n",
    "axes[2, 1].set_title('SwiGLU Gradient',size=20)\n",
    "axes[2, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443ebbb-1555-4894-a0a0-edc7136836a0",
   "metadata": {},
   "source": [
    "- <font color=\"red\">**门控机制为什么高效**？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27011963-9891-416f-90c4-5a28732764d7",
   "metadata": {},
   "source": [
    "门控机制（Gating Mechanism）是深度学习中的一种重要设计，它通过动态选择信息流，提升模型的表达能力和训练效率。相比于单纯的线性变换和激活函数，门控机制更灵活，使模型能够根据输入数据的特性决定哪些信息需要传递、哪些信息需要抑制。\n",
    "\n",
    "| **优势**                   | **解释**                                              |\n",
    "|----------------------------|-------------------------------------------------------|\n",
    "| **避免冗余计算**           | 只让有用的信息通过，抑制无关信息，提升计算效率。       |\n",
    "| **强化非线性表达能力**     | 通过多条路径组合增强模型的表达能力。                   |\n",
    "| **改善梯度流动**           | 减少梯度消失问题，提高深层网络的训练效率。             |\n",
    "| **自适应学习能力**         | 根据不同输入动态选择信息流，提高任务适应性。            |\n",
    "| **多任务场景中的共享能力** | 在多任务或多模态模型中更智能地控制信息流动路径。         |\n",
    "\n",
    "**总结**：门控机制通过**逐元素乘法和动态调控**，使模型能够高效选择性地传递信息，避免了简单线性流程中的冗余计算和信息丢失问题。相比于传统的线性层，门控机制不仅**提高了计算效率**，还增强了模型的**非线性表达能力**和**训练稳定性**，使其在 NLP 和计算机视觉等复杂任务中表现更加优异。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b6b12-d5a5-4d2c-a3ca-96b1b7b228e3",
   "metadata": {},
   "source": [
    "这一函数非常好地展现了门控机制的精髓！受到SwiGLU激活函数的思路影响，LLaMA重新设计了前馈神经网络架构，为原本嵌套的线性层加入了“门控”的逻辑，并且结合了这种逻辑的前馈网络称之为**FFN with SwiGLU**，我将之译为门控前馈神经网络。\n",
    "\n",
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2024LLM/06.png\" alt=\"描述文字\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3f6054-950c-4f1e-96cd-a6d4b7925f73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "不过，在实际实现LLaMA架构的时候，LLaMA官方却没有用广受好评的GELU函数，而是使用了SILU激活函数。**SiLU** 是一种平滑的非线性激活函数，全称为 **Sigmoid-Weighted Linear Unit**。它是由 **Sigmoid 函数**与输入的乘积构成的激活函数，具有较好的梯度流动特性，常用于深度神经网络的激活层中。**SiLU** 在许多深度学习任务中表现优于传统的激活函数（如 ReLU），并且已经被应用在 **Transformer** 等现代架构中（例如，EfficientNet 以及一些 NLP 模型）。\n",
    "\n",
    "$$\n",
    "\\text{SiLU}(x) = x \\cdot \\sigma(x)\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $x$ 是输入值。\n",
    "- $\\sigma(x)$ 是 **Sigmoid** 函数：\n",
    "  $$\n",
    "  \\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "  $$\n",
    "\n",
    "SiLU 的输出是输入 $x$ 和 Sigmoid 函数 $\\sigma(x)$ 的逐元素乘积。\n",
    "\n",
    "**SiLU 的导数（梯度）计算如下**：\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx} \\text{SiLU}(x) = \\sigma(x) + x \\cdot \\sigma(x) \\cdot (1 - \\sigma(x))\n",
    "$$\n",
    "\n",
    "其函数图像与梯度图像如下👇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "573a9945-4f52-4283-8081-08b0ff617e5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义 SiLU 激活函数及其梯度\n",
    "def silu(x):\n",
    "    return x * (1 / (1 + np.exp(-x)))  # SiLU = x * sigmoid(x)\n",
    "\n",
    "def silu_derivative(x):\n",
    "    sigmoid_x = 1 / (1 + np.exp(-x))\n",
    "    return sigmoid_x * (1 + x * (1 - sigmoid_x))  # d(SiLU)/dx\n",
    "\n",
    "# 创建输入数据\n",
    "x = np.linspace(-6, 6, 400)\n",
    "\n",
    "# 计算 SiLU 和其梯度\n",
    "y_silu = silu(x)\n",
    "y_silu_grad = silu_derivative(x)\n",
    "\n",
    "# 绘制 SiLU 激活函数及其梯度\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# SiLU 激活函数图像\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, y_silu, label='SiLU', color='b')\n",
    "plt.title('SiLU Activation Function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('SiLU(x)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# SiLU 梯度图像\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, y_silu_grad, label='Gradient of SiLU', color='r')\n",
    "plt.title('Gradient of SiLU Function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('d(SiLU)/dx')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d4def-095a-4603-a171-d9c560aa949b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "这样的结构被发现非常适应深度神经网络、尤其是Transformer结构，总结一下SiLU激活函数有如下的优点👇\n",
    "\n",
    "1. **更好的梯度流动**：SiLU 在负值区域不会完全输出 0，因此减少了梯度消失和死神经元问题。\n",
    "<br><br>\n",
    "2. **平滑激活**：由于 SiLU 是平滑的，它在训练过程中提供了更平稳的梯度更新，使模型更容易收敛。\n",
    "<br><br>\n",
    "3. **自适应线性和非线性**：对于较大的正值输入，SiLU 的输出接近于线性；而对较小的负值输入，它会进行压缩处理。这种自适应特性增强了模型对复杂模式的捕捉能力。\n",
    "<br><br>\n",
    "4. **计算效率高**：SiLU 的计算复杂度适中，且在现代 GPU/TPU 上的计算效率非常高。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4bb25d-5b7b-4b03-ac76-f911f5e218be",
   "metadata": {},
   "source": [
    "| **特性**        | **ReLU**                       | **GELU**                     | **SiLU**                      |\n",
    "|-----------------|--------------------------------|------------------------------|-------------------------------|\n",
    "| **平滑性**      | 不平滑                         | 平滑                         | 平滑                          |\n",
    "| **负值处理**    | 输出 0                         | 有负值输出                    | 更加平滑的负值输出                    |\n",
    "| **梯度流动**    | 负值区域无梯度                 | 平滑梯度流动                 | 全范围平滑梯度流动            |\n",
    "| **表达能力**    | 适中                           | 强                           | 强，且自适应线性/非线性       |\n",
    "| **计算复杂度**  | 低                             | 较高                         | 适中                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc542c64-5558-4446-bd89-d4f678caa5bd",
   "metadata": {},
   "source": [
    "因此在LLaMA的前馈神经网络中我们实现的实际上是——"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9dbd85-e990-4ce1-a68a-26580ed539fe",
   "metadata": {},
   "source": [
    "> **SwiGLU with Silu**\n",
    "$$\n",
    "\\text{Output} = \\text{Linear2}\n",
    "\\left( \\textcolor{red}{\\text{Silu}}\\left( \\textcolor{green}{\\text{Linear1}}(x) \\right) \n",
    "\\odot \\textcolor{gold}{\\text{Linear3}}(x) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73721f8c-9fdf-4d75-a49d-8a1c3265aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim: int, hidden_dim: int, multiple_of: int, dropout: float):\n",
    "        super().__init__()\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = 4 * dim\n",
    "            hidden_dim = int(2 * hidden_dim / 3)\n",
    "            hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.w2(F.silu(self.w1(x)) * self.w3(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6113bc2-c585-45f6-8903-c55a56a8b4ae",
   "metadata": {},
   "source": [
    "- hidden_dim的系列计算是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49179691-34cd-438c-ace0-a647eb967e19",
   "metadata": {},
   "source": [
    "```python\n",
    "if hidden_dim is None:\n",
    "    hidden_dim = 4 * dim  # Step 1: 设置初始值，通常为输入维度的 4 倍\n",
    "    hidden_dim = int(2 * hidden_dim / 3)  # Step 2: 缩减到 2/3 的大小\n",
    "    hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)  # Step 3: 对齐 multiple_of\n",
    "```\n",
    "\n",
    "这三步的设置逻辑如下：\n",
    "1. **Step 1**：`hidden_dim = 4 * dim`  \n",
    "> 这是常见的做法，类似于 **Transformer** 的前馈网络中使用的隐藏维度。将隐藏层设为输入维度的 4 倍，可以增强网络的非线性表达能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7127e8-8221-4b5b-9e3f-0069d2811f4e",
   "metadata": {},
   "source": [
    "2. **Step 2**：`hidden_dim = int(2 * hidden_dim / 3)` \n",
    "> 这里缩小了隐藏维度，将其减少到 **原值的 2/3**。这一步背后的原因通常是为了**平衡计算开销和模型容量**。隐藏层的维度直接决定了模型的参数量和计算开销。如果按照传统做法设置为 **4 倍的输入维度**，模型可能在某些任务中变得过大，训练和推理的时间复杂度较高。缩减到 2/3，可以**减少 1/3 的参数量**和计算成本，这对于大模型或资源受限的设备非常重要。在一些现代 Transformer 模型（例如 LLaMA）中，缩减隐藏层维度是一种经验优化。研究表明，减少隐藏维度（例如从 $4 \\cdot d$ 缩减到 $\\frac{8}{3} \\cdot d$）往往能在**模型性能和效率之间取得良好平衡**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a30619-eab4-420f-a2c2-dfa4c7ca1598",
   "metadata": {},
   "source": [
    "3. **Step 3**：`hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)`  \n",
    "> 这一步确保隐藏维度是 **multiple_of** 的倍数，以优化 GPU 计算效率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5205713-0df3-4b17-b72c-98fdd42a803f",
   "metadata": {},
   "source": [
    "- multiple_of是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90e965a-b54b-41b1-a2c2-8726a7470898",
   "metadata": {},
   "source": [
    "在FFN实际实现的过程中，multiple_of是我们用来控制hidden_dim大小的关键参数，它代表“你想要让你的hidden_dim能整除某个数吗？”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e030883-c632-4629-947c-0e1cf8a73675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1365"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(2* (4 * 512) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab11c3db-3a62-4d02-9e90-718b18fb0087",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_of = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b9d8597-e925-444c-a408-ffe132b8850b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1368"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_of * ((1365 + multiple_of-1) // multiple_of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ada2bd85-730d-447f-a63e-67f417fbf6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1368//4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf37a7-6a49-49ee-8ae4-49cd59b615d4",
   "metadata": {},
   "source": [
    "## 7. 混合专家网络用于FFN层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b319d40-082e-426f-978f-d438ea7f9251",
   "metadata": {},
   "source": [
    "还记得门控机制是如何操作的吗？当我们在SwiGLU激活函数中，使用一个线性层的输出结果来乘以另一个线性层的结果时，我们把其中一个线性层看作携带信息的层，把另一个线性层看作“门控机制”，以此来压缩数据的通路、逼迫模型筛选出更精准、更重要的信息。\n",
    "\n",
    "$$\n",
    "\\text{SwiGLU}(x) = \\textcolor{red}{\\text{GELU}}\\left( \\textcolor{green}{W_1^a} \\cdot x \\right) \n",
    "\\odot \\textcolor{gold}{W_1^b} \\cdot x\n",
    "$$\n",
    "\n",
    "从门控机制出发我们可以设想，**如果我们不止一扇门呢？这是否意味着我们可以拥有动态的筛选策略？是否意味着我们可以同时筛选出不同、但都非常重要和精准的信息**？就如同卷积神经网络利用不同的卷积核解读不同的信息、注意力机制用不同的头来解读不同的信息一样，门控机制中我们也可以有不同的门来用不同的方式筛选信息，**混合专家模型**因此而诞生，让我们来看看混合专家模型——"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa5528-ccd1-4c00-91a1-f12aa7b8cd48",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2024LLM/16.png\" alt=\"描述文字\" width=\"400\">\n",
    "\n",
    "当我们使用多个门同时控制信息的流通时，这些多个门构成的结构被称为是**路由器**。如图所示，**混合专家模型 (MoE)** 是一种**动态路由**策略，通过为不同的输入选择不同的子模型（专家模型）进行计算。相比于传统的全连接前馈网络（FFN），MoE 在每次前向传播时只激活部分专家模型，从而实现**参数高效**和**计算高效**。动态路由策略是一种在深度学习模型中使用的技术，其核心思想是：根据输入数据的特征动态地选择路径或专家模型来处理信息。与传统模型固定的前向传播路径不同，动态路由策略在每次前向传播时，根据输入的情况选择最合适的子网络、路径或专家来处理数据。这大幅提升了模型的灵活性、计算效率和泛化能力。\n",
    "\n",
    "MoE 已经广泛应用于大规模自然语言处理模型（如 GShard、Switch Transformer 等），并在计算机视觉等领域表现出色。其核心优势在于：**模型具有超大参数量**，但每次推理或训练时，只使用部分参数来进行计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d389f2aa-a040-4d61-b05a-7ea6fa37efb5",
   "metadata": {},
   "source": [
    "- **MoE 的核心公式：**\n",
    "$$\n",
    "\\text{Output} = \\sum_{i=1}^N G_i(x) \\cdot E_i(x)\n",
    "$$\n",
    "> - **$E_i(x)$**：第 $i$ 个专家模型的输出。\n",
    "> - **$G_i(x)$**：由路由器（Gate）计算得到的权重，决定哪些专家应该被激活、每个专家被激活的程度有多大。\n",
    "> - **N**：专家模型的总数。通常来说，我们不会采用全部的专家的结果，而是采用权重最大的top-k个专家的结果，因此在实际计算时，N往往会被k所替代。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e647e6c-b8bd-4722-b65a-469250c1370b",
   "metadata": {},
   "source": [
    "- **主要组件：**\n",
    "> 1. **专家模型（Experts）**：多个全连接层或其他子模型，每个专家处理输入的不同部分或模式。\n",
    "> 2. **路由器（Router/Gate）**：为每个输入选择合适的专家（可以是一个或多个），并为每个被选中的专家分配权重。\n",
    "> 3. **Sparse Activation**：每次计算时，只激活少数几个专家，大幅减少计算开销。在实际计算中，路由器（Gate）不会为所有专家分配非零权重，而是选择Top-k 个权重最高的专家激活。未被激活的专家（即 Top-k 之外的专家）的输出将不会参与计算，它们的权重$G_i(x)$会是0。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab458f66-6622-4bea-ae49-39b24ef35e86",
   "metadata": {},
   "source": [
    "<font color=\"red\">**关键问题1：MoE与Transformer架构或LLaMA架构有什么关系？**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb0d12a-9077-4510-b381-fbf99b1fa673",
   "metadata": {},
   "source": [
    "MoE作为很好的输出模型，可以用于代替**Transformer**中的**前馈网络（FFN）层**。\n",
    "> **提高模型的表达能力**\n",
    "> - 在传统 FFN 中，每一层使用相同的参数处理所有输入。这限制了模型的表达能力。\n",
    "> - 在 MoE 中，不同的专家网络可以学习**不同的模式**，每次处理输入时，动态选择不同的专家来增强模型的灵活性。\n",
    "\n",
    "> **参数量高，但计算量低**\n",
    "> - 使用 MoE 后，模型的总参数量增加，但每次前向传播时，只激活**部分专家**，因此**计算量并不会线性增加**。\n",
    "> - 例如：在 Switch Transformer 中，即使模型拥有 **1.6 万亿参数**，每次推理时只使用不到 1% 的参数。\n",
    "\n",
    "> **增强泛化能力**\n",
    "> - 每个专家专注于学习特定模式，有助于减少模型的**过拟合**，提高模型的泛化能力。\n",
    "\n",
    "> **更有效的计算资源利用**\n",
    "> - 大规模模型训练中，计算资源常常成为瓶颈。MoE 通过**稀疏激活**，让 GPU 或 TPU 只计算少量的专家模型，减少内存占用和计算负担。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2589d25c-adba-474d-991c-6e1372fe9163",
   "metadata": {},
   "source": [
    "<font color=\"red\">**关键问题2：MoE替代FFN层后，MoE具体如何训练？**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a2d75-b44c-4010-ac2c-1069519ac55c",
   "metadata": {},
   "source": [
    "在训练时，模型需要不断调整**所有专家的参数**，并保证路由器能够学会为不同输入选择合适的专家。因此，训练过程比推理要复杂得多，需要更多的计算资源和优化。\n",
    "\n",
    "> **MoE的训练流程**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe70307-0b7e-429f-af06-da9f7ae2e68a",
   "metadata": {},
   "source": [
    "1. **输入数据准备**：输入数据通过模型的编码层或其他层，产生**隐状态 (hidden states)**，作为路由器和专家模型的输入。<br><br>\n",
    "\n",
    "2. **路由器（Gate）计算权重**：路由器根据输入数据，计算每个专家的**激活权重**。使用 **softmax** 或其他激活函数计算每个专家的得分（`G_i(x)`），然后通过 **top-k** 筛选出权重最大的专家。<br><br>\n",
    "\n",
    "3. **选择 Top-k 专家**：使用 `torch.topk()` 函数，选择 **top-k** 个得分最高的专家。只有这 **k** 个专家参与向前传播的计算，其他专家的输出会被忽略（权重为 0）。<br><br>\n",
    "\n",
    "4. **专家计算输出**：被选中的 **Top-k** 专家根据输入数据计算它们的输出。路由器的权重用于对这些输出进行**加权求和**。<br><br>\n",
    "\n",
    "5. **损失计算与辅助损失（Auxiliary Loss）**：除了常规损失（如交叉熵），还引入**辅助损失**，确保所有专家都能被均衡使用，避免某些专家“过度使用”或“闲置”。<br><br>\n",
    "\n",
    "6. **反向传播与参数更新**：使用反向传播更新所有专家的参数，以及路由器的参数。即使某些专家在当前 batch 中未被激活，它们的参数也可能因为**累积梯度**而被更新。<br><br>\n",
    "\n",
    "注意，在一次前向传播中，未被激活的专家不会参与计算，因此它们的梯度也不会直接更新。但是，模型通常会在多个 batch 或不同输入中均衡地激活不同的专家，因此所有专家的参数会在整个训练过程中得到更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4754e05b-437a-4ade-a46b-84994671e4bf",
   "metadata": {},
   "source": [
    "> **谁决定了专家是否被激活？哪个层次的信息在选择专家？**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e864149-0c02-4784-b450-4c734077d687",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "在**混合专家模型 (MoE)** 中，由于其**稀疏激活机制**，专家的选择并非针对于整个批次的整体输出，而是**针对每个 token（或时间步）进行选择和计算**的。这就是为什么一个专家的激活频率会是基于**每个 token** 或 **每个时间步**来统计的。\n",
    "\n",
    "在引入 **MoE** 后，模型会为**每个 token 或每个时间步单独计算路由器输出**，从而决定该 token 应该使用哪些专家。这意味着：\n",
    "\n",
    "  - **每个 token 或每个位置**的计算会激活不同的专家。\n",
    "  - 每个专家在同一批次的不同 token 上可能会被多次激活。\n",
    "\n",
    "因此，在 MoE 中，<font color=\"red\">**专家的选择是基于每个 token 进行的，而不是基于整个序列或批次**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f32f28-5529-4f45-8f8f-c758795abb48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "Input sequence: [Token_1, Token_2, Token_3, Token_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95899fa8-4584-494b-989f-5a2aa8d221ad",
   "metadata": {},
   "source": [
    "对于每个 token，路由器可能会选择不同的专家：\n",
    "\n",
    "Token_1：选择专家 1 和专家 3。<br>\n",
    "Token_2：选择专家 2 和专家 3。<br>\n",
    "Token_3：选择专家 1 和专家 4。<br>\n",
    "Token_4：选择专家 2 和专家 1。<br>\n",
    "\n",
    "在这个例子中，专家 1 被激活了 3 次（分别在 Token_1、Token_3 和 Token_4 上）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4540a1-e2d3-48bf-b7ec-5e3a9dc595be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "那为什么专家的选择是基于每个 token 而非整张表？这是因为 Transformer 模型中的每个 token 的特征可能不同，而**MoE 的目标是为不同的特征选择最适合的专家**。具体来说：\n",
    "\n",
    "- **路由器**会根据每个 token 的输入特征计算 softmax 得分，并为每个 token 选择 Top-k 个专家。\n",
    "- 这样可以确保模型的不同部分专注于处理特定类型的特征，例如：\n",
    "  - 某个专家可能擅长处理动词结构。\n",
    "  - 另一个专家可能擅长处理名词短语。\n",
    "\n",
    "这种 **“按 token” 的专家选择机制** 提高了模型的表达能力和灵活性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc6127c-ae66-46c2-89b1-8c81cacadca1",
   "metadata": {},
   "source": [
    "> **瓶颈问题**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981b541-f5e8-4738-96c9-3e65027f1f75",
   "metadata": {},
   "source": [
    "少数专家成为“**瓶颈**”是**混合专家模型 (MoE)** 中常见的问题之一。在 MoE 中，路由器（Gate）会为每个输入选择一部分专家（如 Top-k 个）来处理当前任务。然而，由于**数据分布不均**或路由器的偏向性、以及训练的偶然性，实际中可能会出现以下几种情况：\n",
    "\n",
    "1. **专家的偏向性**：由于路由器的训练偏差，某些专家会被频繁激活，而其他专家几乎从不被使用。\n",
    "2. **激活不均衡**：一些专家会承载大部分计算负担，而其他专家却“闲置”，无法获得足够的训练机会。\n",
    "3. **参数更新不充分**：未被激活的专家参数得不到更新，导致这些专家无法在模型训练中发挥作用。\n",
    "\n",
    "这样的情况被称为“专家瓶颈”，这可能导致——\n",
    "\n",
    "- **负载不均衡**：瓶颈专家承载过多的计算负担，而其他专家闲置，导致模型整体计算资源未能高效利用。\n",
    "- **训练效果下降**：频繁被激活的专家过度训练，可能出现**过拟合**，而其他专家则由于长期未被激活导致参数更新不足，导致模型的泛化能力下降。\n",
    "- **模型退化**：随着训练的进行，未被激活的专家无法学习到有用的特征，进而降低整个模型的表现。\n",
    "\n",
    "为了解决**专家瓶颈**问题，通常引入一种称为**辅助损失（Auxiliary Loss）**的机制，用来**均衡专家的使用频率**，确保所有专家都能在训练中获得足够的激活机会。这种辅助损失会被叠加在神经网络的主要损失（如交叉熵损失、MSE 等）上，它在训练过程中与主要损失一起影响模型的反向传播和参数更新。这种设计确保模型在优化主要任务的同时，也能够实现一些额外的目标，比如均衡专家的使用频率、提升模型的泛化能力。\n",
    "\n",
    "当存在辅助损失时，总损失的计算公式为：\n",
    "\n",
    "$$\\text{Total Loss} = \\text{Main Loss} + \\alpha \\cdot \\text{Auxiliary Loss}$$\n",
    "\n",
    "其中$\\alpha$是用来控制平衡的超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b445fe92-dcdb-4590-bd0e-3a7b6af2977a",
   "metadata": {},
   "source": [
    "<font color=\"red\">**关键问题3：MoE模型的推理过程是怎样的？为什么说MoE可以更快地推理？**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bbd2f2-518c-43f9-8e9b-dcd1fc640993",
   "metadata": {},
   "source": [
    "在推理阶段，模型只需要一次前向传播来获得输出，不需要计算梯度，因此计算量和内存需求更小。稀疏激活在推理中的作用尤为明显。\n",
    "\n",
    "> **MoE 推理流程：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728c81a-7506-4ceb-bb58-8e01ca278eb8",
   "metadata": {},
   "source": [
    "1. **输入数据通过路由器**：输入数据经过路由器，路由器根据当前输入，计算每个专家的得分（`G_i(x)`）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002250ae-424f-4ec9-a814-16ede2e0e5ff",
   "metadata": {},
   "source": [
    "2. **激活 Top-k 专家**：路由器选择 **Top-k** 个得分最高的专家，并忽略其他专家。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265e68d-c930-455c-8e55-6754e9a900c9",
   "metadata": {},
   "source": [
    "3. **Top-k 专家输出计算**：只有这 **Top-k** 个专家参与计算，其他专家的输出为 0，减少了计算开销。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182bb761-20a9-4e69-b502-4dc61401e09e",
   "metadata": {},
   "source": [
    "4. **加权求和得到最终输出**：路由器对这 **Top-k** 个专家的输出进行**加权求和**，得到模型的最终输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284d8d08-4f9c-43aa-b279-d2bcb2e0faaa",
   "metadata": {},
   "source": [
    "> **很显然，MoE的推理过程比常规线性层的推理流程快很多——**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd1e72d-9d61-4be5-8180-867a0f8e8617",
   "metadata": {},
   "source": [
    "1. **稀疏激活减少计算**：在推理时，只计算 **Top-k** 个专家的输出，未被激活的专家不会进行计算，从而大幅减少计算量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63daf3b-9bf5-4b04-b273-9b2c1ecadc64",
   "metadata": {},
   "source": [
    "2. **内存占用减少**：由于只计算部分专家的输出，内存占用大幅减少。这尤其适用于**大模型**，如 Switch Transformer，在保持模型大容量的同时减少推理时的内存占用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970678cd-0999-4a9d-8a0b-3e3c3aac7d86",
   "metadata": {},
   "source": [
    "| **阶段**        | **训练**                                  | **推理**                                  |\n",
    "|----------------|-------------------------------------------|------------------------------------------|\n",
    "| **激活专家数**  | Top-k 专家参与计算，但所有专家更新参数      | 只激活 Top-k 专家，其他专家不计算         |\n",
    "| **反向传播**    | 需要反向传播和梯度计算                     | 不需要梯度计算                            |\n",
    "| **内存占用**    | 高（需要存储所有专家的参数和梯度）           | 低（只需要存储部分专家的输出）             |\n",
    "| **计算量**      | 高（所有专家的梯度都可能被更新）             | 低（只计算部分专家的输出）                 |\n",
    "| **负载均衡**    | 需要负载均衡，避免专家使用不均              | 不需要，因为只需一次前向传播               |\n",
    "| **跨设备通信**  | 需要频繁的跨设备通信                       | 通信需求较低                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8690fe5e-2a4e-4357-b01d-658322486f73",
   "metadata": {},
   "source": [
    "<font color=\"red\">**关键问题4：MoE模型可用的aux_loss函数有哪些？具体如何实现？**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e9896-412b-4125-9381-062ddac8fbcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "在 **Mixture of Experts (MoE)** 模型中，常见的辅助损失（auxiliary loss）用于帮助训练过程中的专家选择更加平衡，防止某些专家被过度选择或其他专家很少被选中。以下是几种常见的 MoE 辅助损失的例子：\n",
    "\n",
    "- 1. **负载平衡损失 (Load Balancing Loss)**：促进不同专家的负载更加平衡，避免过度依赖某个专家。一种常见的形式是使用专家的选择频率与分配的均衡性来构造。通常，目标是让每个专家的选择概率与理想的均匀分布更接近。\n",
    "     $$\n",
    "     \\text{aux\\_loss} = \\sum_{i=1}^{N} f_i \\log(f_i)\n",
    "     $$\n",
    "     其中 $ f_i $ 是第 $ i $ 个专家被选择的频率。\n",
    "<br><br>\n",
    "- 2. **基于熵的损失 (Entropy-based Loss)**：通过增加专家选择的熵，鼓励模型选择更多的专家来参与计算，从而减少某些专家的过载。\n",
    "     $$\n",
    "     \\text{aux\\_loss} = - \\sum_{i=1}^{N} P_i \\log(P_i)\n",
    "     $$\n",
    "     其中 $ P_i $ 是分配给第 $ i $ 个专家的概率。熵越高，说明分配越均匀。\n",
    "<br><br>\n",
    "- 3. **KL 散度损失 (KL Divergence Loss)**：将实际的专家选择分布与理想的均匀分布进行比较。\n",
    "     $$\n",
    "     \\text{aux\\_loss} = \\text{KL}(P || U)\n",
    "     $$\n",
    "     其中 $ P $ 是模型计算出的专家分配概率分布，$ U $ 是理想的均匀分布。通过最小化 KL 散度，确保专家选择接近均匀分布，避免某些专家被过度使用。\n",
    "<br><br>\n",
    "- 4. **专家负载正则化 (Expert Load Regularization)**：控制每个专家的负载，使得负载接近于模型的理想目标负载，比如让每个专家处理相同数量的样本。\n",
    "     $$\n",
    "     \\text{aux\\_loss} = \\sum_{i=1}^{N} (\\text{load}_i - \\text{target\\_load})^2\n",
    "     $$\n",
    "     其中 $ \\text{load}_i $ 是第 $ i $ 个专家的实际负载，$ \\text{target\\_load} $ 是理想的负载。\n",
    "\n",
    "这些辅助损失有助于 MoE 模型在分配专家时更加有效，平衡负载并避免某些专家过度工作或闲置。具体的实现和选择取决于模型的需求和场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c917512-62d3-4da3-947d-2418d9980720",
   "metadata": {},
   "source": [
    "- **实际使用的损失函数**\n",
    "\n",
    "在进行实践时，我们可以使用**专家的平均权重**和**平均使用率**来平衡专家的选择。比如说——\n",
    "\n",
    "$$\n",
    "\\text{aux\\_loss} = \\alpha \\times \\sum_{i=1}^{N_{\\text{routed\\_experts}}} (P_i \\cdot f_i)\n",
    "$$\n",
    "\n",
    "- $ N_{\\text{routed\\_experts}} $ 是专家的数量。\n",
    "- $ P_i $ 是所有专家的平均权重。\n",
    "- $ f_i $ 是专家的平均使用率。\n",
    "- 最后的辅助损失是所有专家的分配概率和使用频率乘积的加权求和，用参数 $ \\alpha $ 来缩放损失。\n",
    "\n",
    "这种方法类似于在负载平衡中的一个更直接的版本，避免了 `log` 函数的使用，这样可以让代码运行更快速，另外也可以让损失不那么敏感。`log` 函数通常用于拉伸分布，使得损失函数对极值更加敏感。在实现时如果直接使用每个专家的概率和使用频率的乘积，是一种较为简单的方式来衡量专家的平衡性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e11a855-1ab6-4c41-93f3-2a6a61cba81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import struct\n",
    "import inspect\n",
    "import time\n",
    "\n",
    "import LMConfig\n",
    "from typing import Any, Optional, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from transformers import PreTrainedModel\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5cd15d67-4187-41b2-a214-a133d3be1b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6675000000000001, 0.6631250000000001, 0.8775000000000001)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义三个权重矩阵和对应的 top-k 矩阵\n",
    "# 非常均衡、但是每个专家对每个token的处理高度类似\n",
    "# 没有实现专家的特异化\n",
    "weights_1 = np.array([\n",
    "    [0.34, 0.34, 0.32],\n",
    "    [0.34, 0.32, 0.34],\n",
    "    [0.34, 0.34, 0.32],\n",
    "    [0.32, 0.34, 0.34]\n",
    "])\n",
    "\n",
    "topk_1 = np.array([\n",
    "    [1, 1, 0],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "    [0, 1, 1]\n",
    "])\n",
    "\n",
    "# 每个专家都有被用到，也实现了一定的特异化\n",
    "weights_2 = np.array([\n",
    "    [0.6, 0.25, 0.15],\n",
    "    [0.4, 0.4, 0.2],\n",
    "    [0.3, 0.6, 0.1],\n",
    "    [0.04, 0.06, 0.9]\n",
    "])\n",
    "\n",
    "topk_2 = np.array([\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 0],\n",
    "    [0, 1, 1]\n",
    "])\n",
    "\n",
    "# 不均衡，只有专家1和专家2被使用\n",
    "weights_3 = np.array([\n",
    "    [0.6, 0.25, 0.15],\n",
    "    [0.4, 0.4, 0.2],\n",
    "    [0.3, 0.6, 0.1],\n",
    "    [0.9, 0.06, 0.04]\n",
    "])\n",
    "\n",
    "topk_3 = np.array([\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 0]\n",
    "])\n",
    "\n",
    "# 定义计算 Pi * fi 的函数\n",
    "def calculate_aux_loss(weights, topk):\n",
    "    Pi = weights.mean(axis=0)  # 计算纵向均值 Pi\n",
    "    fi = topk.mean(axis=0)     # 计算纵向均值 fi\n",
    "    Pi_fi = Pi * fi            # 计算 Pi * fi\n",
    "    return Pi_fi.sum()         # 返回 aux_loss\n",
    "\n",
    "# 计算三个 aux_loss\n",
    "aux_loss_1 = calculate_aux_loss(weights_1, topk_1)\n",
    "aux_loss_2 = calculate_aux_loss(weights_2, topk_2)\n",
    "aux_loss_3 = calculate_aux_loss(weights_3, topk_3)\n",
    "\n",
    "aux_loss_1, aux_loss_2, aux_loss_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5298972-43d3-4650-a324-6339b5c476b1",
   "metadata": {},
   "source": [
    "- **代码中的Pi计算与Fi计算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c33dd4ed-0b24-4f51-a7a1-9451ed3cd2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 6])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsz = 3\n",
    "seq_len = 10\n",
    "\n",
    "#从所有专家那里获得的输出结果\n",
    "hidden_states = torch.randn(size=(30,512))\n",
    "\n",
    "#权重的初始化参数\n",
    "self_weight = torch.randn(size=(6,512))\n",
    "\n",
    "#利用线性层将二者相连，构建每个token上每个专家的权重\n",
    "weights = F.linear(hidden_states, self_weight, None)\n",
    "\n",
    "weights.shape #每个token在每个专家上的得分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "79ab3829-0a37-4135-9ba8-5c4b62f902e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-12.3657,  17.0877, -18.9656,  -8.8610,  44.1774,  30.1824],\n",
       "        [ 20.3411, -20.2856,   1.4306,  -5.1553,   2.7279,  -2.8289],\n",
       "        [  1.5791,  -5.1779, -45.0106,  28.4815,  14.1131,  -3.5699],\n",
       "        [-18.1684,  10.7702, -22.4980,   8.7829,   5.4515, -14.3356],\n",
       "        [-33.1890, -11.0316,  19.4646,   6.2980,  44.6038, -15.4577],\n",
       "        [-20.9658,  -6.7193, -15.1916,  21.5101,  -9.6914,   8.9385],\n",
       "        [ 36.5068,  11.9159,   9.3812,   2.3989,  19.6420,  -0.6567],\n",
       "        [ 13.4714,   3.1922,  23.7547, -38.6351,  -5.8330, -32.6042],\n",
       "        [ 43.8076, -15.1372,   2.0251,  -3.8141, -32.4383, -41.9985],\n",
       "        [  9.6094,  22.0590,  11.4946,   7.4589,  -6.5452,  -1.9821],\n",
       "        [ 37.4659,   1.6940, -14.2333,  21.4023,  31.5325,  25.8175],\n",
       "        [ 28.4776,   1.7487, -18.7158,  49.3381, -25.5030,  18.6360],\n",
       "        [ 67.0392,  -3.3171, -47.9532,  25.3408, -21.9846,  26.7697],\n",
       "        [-19.9617,  54.8721,  -1.5347, -11.1723, -17.6458,  -1.9065],\n",
       "        [-37.7005,   1.4074,  20.0198,  47.6124,   1.0387,   3.5430],\n",
       "        [ -8.1231, -22.7816,  19.9131,  -1.6460, -33.2116,  31.5127],\n",
       "        [ -7.8739,  -3.8522,  12.1932,  36.7933,   5.8989,  14.5877],\n",
       "        [ 10.8363,  -3.0343,   9.7497, -35.1124,  -0.9021, -10.6730],\n",
       "        [ 31.9515, -26.2520,  16.4225, -20.8261, -29.7659,  -5.2601],\n",
       "        [  5.7797,  15.4843,  -1.3180,  21.4633,  -9.0845,  -0.9449],\n",
       "        [  0.9538, -24.4142, -12.5256,  40.1085,  15.4030,  -6.4359],\n",
       "        [  6.8480,  25.3027,  -3.0385,   5.7115,  -4.5227,   0.5160],\n",
       "        [ 14.6567,  -8.0604, -11.7071, -30.9817,  -4.3033, -15.3558],\n",
       "        [  7.5315,  -4.7601, -10.3903, -39.3860,  -7.1358,  -2.9154],\n",
       "        [ -0.6197, -11.2035,  21.6629, -48.8763,  -1.5226, -28.6114],\n",
       "        [  1.3166,  -2.1577,  -3.1116,  21.3182,  15.3025,  -8.2563],\n",
       "        [-12.8069, -48.3889,   7.3314,   4.0233,  24.4738,  18.6199],\n",
       "        [ -7.1883,  -1.1726, -24.3772,  54.2391, -19.9052,  14.7075],\n",
       "        [ 25.6107,  -6.9439,  -2.6833, -17.3397,  26.0228,  52.3016],\n",
       "        [-22.6098, -30.1528,   7.1860,  -0.5940, -18.1783,  10.4084]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights #在这基础上求均值就是Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e5ca61-13fa-47ae-8d9c-7dbf1cc55f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求解topK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c23c61fb-e041-48e6-9ebf-715774741791",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights.softmax(-1) #6个专家的得分总和被归一化到[0,1]之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "077c5efd-be0b-4b88-82ee-359d5d6ef6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_weight, topk_idx = torch.topk(weights, k=2, dim=-1, sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e6337f30-f47d-45ca-a5eb-6ebba04bcdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.8320e-01, 1.6795e-02],\n",
       "        [9.9403e-01, 5.9744e-03],\n",
       "        [9.8880e-01, 1.1198e-02],\n",
       "        [9.9991e-01, 5.1956e-05],\n",
       "        [7.7478e-01, 2.2522e-01],\n",
       "        [9.9998e-01, 1.7492e-05],\n",
       "        [1.0000e+00, 8.1331e-07],\n",
       "        [1.0000e+00, 1.6485e-13],\n",
       "        [9.9999e-01, 1.0975e-05],\n",
       "        [1.0000e+00, 2.4947e-07],\n",
       "        [1.0000e+00, 6.5668e-10],\n",
       "        [1.0000e+00, 4.6358e-06],\n",
       "        [9.6342e-01, 3.6527e-02],\n",
       "        [7.5047e-01, 2.4953e-01],\n",
       "        [1.0000e+00, 5.1874e-10],\n",
       "        [1.0000e+00, 2.2371e-15],\n",
       "        [1.0000e+00, 4.7236e-19],\n",
       "        [9.9774e-01, 1.5608e-03],\n",
       "        [9.9731e-01, 2.6825e-03],\n",
       "        [1.0000e+00, 3.0291e-24],\n",
       "        [1.0000e+00, 6.3939e-15],\n",
       "        [9.9961e-01, 3.8797e-04],\n",
       "        [1.0000e+00, 6.4792e-12],\n",
       "        [1.0000e+00, 1.2438e-16],\n",
       "        [6.1678e-01, 3.8322e-01],\n",
       "        [9.9997e-01, 2.5446e-05],\n",
       "        [1.0000e+00, 6.9169e-11],\n",
       "        [9.9994e-01, 6.0623e-05],\n",
       "        [7.7002e-01, 2.2997e-01],\n",
       "        [9.8577e-01, 1.4225e-02]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_weight #每个token效果最好的两个专家上的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ad0ddf1-67b0-4da2-86c1-89390e9e6ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [2, 1],\n",
       "        [5, 0],\n",
       "        [2, 3],\n",
       "        [0, 4],\n",
       "        [3, 1],\n",
       "        [5, 3],\n",
       "        [2, 5],\n",
       "        [2, 5],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [1, 5],\n",
       "        [1, 0],\n",
       "        [1, 3],\n",
       "        [5, 2],\n",
       "        [3, 0],\n",
       "        [2, 1],\n",
       "        [3, 1],\n",
       "        [4, 5],\n",
       "        [2, 1],\n",
       "        [5, 4],\n",
       "        [3, 1],\n",
       "        [2, 3],\n",
       "        [3, 2],\n",
       "        [2, 4],\n",
       "        [5, 0],\n",
       "        [5, 0],\n",
       "        [1, 0],\n",
       "        [0, 5],\n",
       "        [4, 0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_idx #每个token激活的前2个专家"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1e9bb144-2d3e-4af6-91c4-f47f341e80d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拓展成类似于one-hot的结构\n",
    "topk_idx_for_aux_loss = topk_idx.view(3, -1)\n",
    "topk_idx_for_aux_loss.shape\n",
    "mask_ce = F.one_hot(topk_idx_for_aux_loss.view(-1), num_classes=6)\n",
    "\n",
    "mask_ce #Fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f4dcd-7623-4b42-bbc7-a986b380fc5f",
   "metadata": {},
   "source": [
    "<font color=\"red\">**关键问题5：MoE模型的具体实现**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ce3ef-7c69-445b-aed5-4bddb3959f5d",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2024LLM/16.png\" alt=\"描述文字\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa2c7722-4009-499a-bc8e-c013148337ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class MoEGate(nn.Module):\n",
    "    def __init__(self, config: LMConfig):\n",
    "        \"\"\"\n",
    "        初始化 MoEGate 类，用于混合专家模型中的门控机制。\n",
    "\n",
    "        参数：\n",
    "        - config: LMConfig 对象，包含模型的配置信息，如专家数量、得分函数、辅助损失等。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.config = config  # 保存配置信息\n",
    "        self.top_k = config.num_experts_per_tok  # 每次选择的 top-k 个专家数量\n",
    "        self.n_routed_experts = config.n_routed_experts  # 总的专家数量\n",
    "\n",
    "        self.scoring_func = config.scoring_func  # 路由器使用的得分函数（如 softmax）\n",
    "        self.alpha = config.aux_loss_alpha  # 辅助损失的系数\n",
    "        self.seq_aux = config.seq_aux  # 是否启用基于序列的辅助损失\n",
    "\n",
    "        self.norm_topk_prob = config.norm_topk_prob  # 是否对 top-k 权重进行归一化\n",
    "        # 每个专家被给与的权重的维度\n",
    "        self.gating_dim = config.dim  # 输入维度\n",
    "        # 路由器的权重矩阵：用于计算每个专家的得分\n",
    "        self.weight = nn.Parameter(torch.empty((self.n_routed_experts, self.gating_dim)))\n",
    "        self.reset_parameters()  # 初始化权重参数\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"\n",
    "        使用 Kaiming 初始化方法对权重矩阵进行初始化，确保模型在深层网络中有较好的梯度流动。\n",
    "        \"\"\"\n",
    "        import torch.nn.init as init\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))  # Kaiming 初始化\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        \"\"\"\n",
    "        前向传播：根据输入的隐状态（hidden_states）计算专家的得分，选择 top-k 个专家，\n",
    "        并在训练时计算辅助损失。\n",
    "\n",
    "        参数：\n",
    "        - hidden_states: Tensor，形状为 (batch_size, seq_len, hidden_dim) 的输入张量。\n",
    "\n",
    "        返回：\n",
    "        - topk_idx: 被选中的 top-k 个专家的索引。\n",
    "        - topk_weight: 这些专家对应的权重。\n",
    "        - aux_loss: 在训练模式下返回的辅助损失（否则为 None）。\n",
    "        \"\"\"\n",
    "        # 获取 batch 大小、序列长度和隐藏维度\n",
    "        bsz, seq_len, h = hidden_states.shape\n",
    "\n",
    "        # 将输入重塑为二维张量 (batch_size * seq_len, hidden_dim)\n",
    "        hidden_states = hidden_states.view(-1, h)\n",
    "\n",
    "        # 使用线性层计算每个专家的得分，token-level (n_routed_experts, gating_dim) -> (batch_size * seq_len, n_routed_experts)\n",
    "        logits = F.linear(hidden_states, self.weight, None)\n",
    "\n",
    "        # 根据配置，使用 softmax 对得分进行归一化处理\n",
    "        if self.scoring_func == 'softmax':\n",
    "            scores = logits.softmax(dim=-1)  # 按照最后一维计算 softmax\n",
    "        else:\n",
    "            raise NotImplementedError(f'insupportable scoring function for MoE gating: {self.scoring_func}')\n",
    "\n",
    "        # 获取 top-k 专家的权重和对应的索引\n",
    "        topk_weight, topk_idx = torch.topk(scores, k=self.top_k, dim=-1, sorted=False)\n",
    "\n",
    "        # 如果启用归一化，则对 top-k 权重进行归一化处理\n",
    "        if self.top_k > 1 and self.norm_topk_prob:\n",
    "            # 避免除以 0，添加小数项 1e-20\n",
    "            denominator = topk_weight.sum(dim=-1, keepdim=True) + 1e-20\n",
    "            topk_weight = topk_weight / denominator\n",
    "\n",
    "        # 如果在训练模式下且辅助损失系数 alpha > 0，则计算辅助损失\n",
    "        if self.training and self.alpha > 0.0:\n",
    "            scores_for_aux = scores  # 获取所有专家的得分用于辅助损失计算\n",
    "            aux_topk = self.top_k  # 辅助损失中使用的 top-k 专家数量\n",
    "            # 将 top-k 专家的索引重塑为 (batch_size, top_k * seq_len)\n",
    "            topk_idx_for_aux_loss = topk_idx.view(bsz, -1)\n",
    "\n",
    "            if self.seq_aux:\n",
    "                # 如果启用了序列级别的辅助损失\n",
    "                scores_for_seq_aux = scores_for_aux.view(bsz, seq_len, -1)\n",
    "\n",
    "                # 初始化交叉熵损失的张量\n",
    "                ce = torch.zeros(bsz, self.n_routed_experts, device=hidden_states.device)\n",
    "\n",
    "                # 按照每个序列来计算，计算每个序列所对应的所有专家权重\n",
    "                ce.scatter_add_(\n",
    "                    1, topk_idx_for_aux_loss,\n",
    "                    torch.ones(bsz, seq_len * aux_topk, device=hidden_states.device)\n",
    "                ).div_(seq_len * aux_topk / self.n_routed_experts)\n",
    "\n",
    "                # 计算序列级别的辅助损失\n",
    "                aux_loss = (ce * scores_for_seq_aux.mean(dim=1)).sum(dim=1).mean() * self.alpha\n",
    "            else:\n",
    "                # 如果没有启用序列级别的辅助损失\n",
    "                # 使用 one-hot 编码标记被选中的专家\n",
    "                mask_ce = F.one_hot(topk_idx_for_aux_loss.view(-1), num_classes=self.n_routed_experts)\n",
    "                ce = mask_ce.float().mean(0)  # 计算每个专家的平均使用率\n",
    "\n",
    "                Pi = scores_for_aux.mean(0)  # 所有专家的平均分配概率\n",
    "                fi = ce * self.n_routed_experts  # 专家使用频率\n",
    "                aux_loss = (Pi * fi).sum() * self.alpha  # 计算辅助损失\n",
    "        else:\n",
    "            aux_loss = None  # 如果不在训练模式或 alpha=0，则不计算辅助损失\n",
    "\n",
    "        # 返回 top-k 专家的索引、对应权重和辅助损失\n",
    "        return topk_idx, topk_weight, aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "723a575d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "arry = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(arry.repeat_interleave(2, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92e79925-c159-4c87-ba6f-332478852325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MOEFeedForward(nn.Module):\n",
    "    def __init__(self, config: LMConfig):\n",
    "        \"\"\"\n",
    "        初始化 MOEFeedForward 类。\n",
    "        \n",
    "        参数：\n",
    "        - config: 包含模型配置的 LMConfig 对象，包括专家数量、维度、隐藏层维度和 dropout 参数。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # 创建多个专家网络的列表 (ModuleList)，每个专家是一个 FeedForward 层\n",
    "        self.experts = nn.ModuleList([\n",
    "            FeedForward(\n",
    "                dim=config.dim,\n",
    "                hidden_dim=config.hidden_dim,\n",
    "                multiple_of=config.multiple_of,\n",
    "                dropout=config.dropout,\n",
    "            )\n",
    "            for _ in range(config.n_routed_experts)  # n_routed_experts：总专家数量\n",
    "        ])\n",
    "\n",
    "        # 创建门控 (Gate) 对象，用于选择哪些专家参与计算\n",
    "        self.gate = MoEGate(config)\n",
    "\n",
    "        # 如果配置指定了共享专家，则代表允许MoE与FeedForward并联\n",
    "        if config.n_shared_experts is not None:\n",
    "            self.shared_experts = FeedForward(\n",
    "                dim=config.dim,\n",
    "                hidden_dim=config.hidden_dim,\n",
    "                multiple_of=config.multiple_of,\n",
    "                dropout=config.dropout,\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播逻辑。\n",
    "\n",
    "        参数：\n",
    "        - x: 输入张量，形状为 (batch_size, seq_len, hidden_dim)。\n",
    "\n",
    "        返回：\n",
    "        - y: 输出张量，经过专家网络和共享专家（如果存在）的计算。\n",
    "        \"\"\"\n",
    "        identity = x  # 保存原始输入（用于后续的残差连接）\n",
    "        orig_shape = x.shape  # 保存原始输入的形状信息\n",
    "        bsz, seq_len, _ = x.shape  # 获取批次大小、序列长度和隐藏层维度\n",
    "\n",
    "        # 使用门控机制选择参与计算的专家\n",
    "        topk_idx, topk_weight, aux_loss = self.gate(x)  # topk_idx: 选中的专家索引，topk_weight: 选中的专家权重\n",
    "\n",
    "        # 将输入数据重塑为 (batch_size * seq_len, hidden_dim)\n",
    "        x = x.view(-1, x.shape[-1])  \n",
    "        flat_topk_idx = topk_idx.view(-1)  # 将专家索引展平成一维\n",
    "\n",
    "        if self.training:\n",
    "            # 训练模式下，重复输入数据以适应专家数量\n",
    "            x = x.repeat_interleave(self.config.num_experts_per_tok, dim=0)\n",
    "\n",
    "            # 创建用于存储专家输出的张量\n",
    "            y = torch.empty_like(x, dtype=torch.float16)\n",
    "\n",
    "            # 遍历每个专家，将符合条件的 token 输入到对应专家中\n",
    "            for i, expert in enumerate(self.experts):\n",
    "                y[flat_topk_idx == i] = expert(x[flat_topk_idx == i])  # 仅处理属于该专家的 token\n",
    "\n",
    "            # 计算每个 token 的加权输出\n",
    "            y = (y.view(*topk_weight.shape, -1) * topk_weight.unsqueeze(-1)).sum(dim=1)\n",
    "            y = y.view(*orig_shape)  # 恢复为原始输入的形状\n",
    "        else:\n",
    "            # 推理模式下，只选择最优专家\n",
    "            y = self.moe_infer(x, flat_topk_idx, topk_weight.view(-1, 1)).view(*orig_shape)\n",
    "\n",
    "        # 如果有共享专家，将共享专家的输出与 y 相加（残差连接）\n",
    "        if self.config.n_shared_experts is not None:\n",
    "            y = y + self.shared_experts(identity)\n",
    "\n",
    "        return y\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def moe_infer(self, x, flat_expert_indices, flat_expert_weights):\n",
    "        \"\"\"\n",
    "        推理模式下的专家计算逻辑。\n",
    "\n",
    "        参数：\n",
    "        - x: 输入张量，形状为 (batch_size * seq_len, hidden_dim)。\n",
    "        - flat_expert_indices: 展平后的专家索引，用于指示哪些 token 属于哪些专家。\n",
    "        - flat_expert_weights: 展平后的专家权重，用于加权专家的输出。\n",
    "\n",
    "        返回：\n",
    "        - expert_cache: 经过专家计算后的输出张量。\n",
    "        \"\"\"\n",
    "        # 创建一个与输入形状相同的张量，用于存储专家输出\n",
    "        expert_cache = torch.zeros_like(x)\n",
    "\n",
    "        # 对专家索引进行排序，以便批量处理属于同一专家的 token\n",
    "        idxs = flat_expert_indices.argsort()\n",
    "\n",
    "        # 计算每个专家需要处理的 token 数量，并累积求和以找到每个专家的范围\n",
    "        tokens_per_expert = flat_expert_indices.bincount().cpu().numpy().cumsum(0)\n",
    "\n",
    "        # 将排序后的索引映射回 token 的原始位置\n",
    "        token_idxs = idxs // self.config.num_experts_per_tok\n",
    "\n",
    "        # 遍历每个专家，处理属于该专家的 token\n",
    "        for i, end_idx in enumerate(tokens_per_expert):\n",
    "            # 获取每个专家的 token 范围\n",
    "            start_idx = 0 if i == 0 else tokens_per_expert[i - 1]\n",
    "\n",
    "            # 如果该专家没有处理任何 token，则跳过\n",
    "            if start_idx == end_idx:\n",
    "                continue\n",
    "\n",
    "            # 获取该专家对象\n",
    "            expert = self.experts[i]\n",
    "\n",
    "            # 获取属于该专家的 token 索引和对应的 token\n",
    "            exp_token_idx = token_idxs[start_idx:end_idx]\n",
    "            expert_tokens = x[exp_token_idx]\n",
    "\n",
    "            # 通过专家计算 token 的输出\n",
    "            expert_out = expert(expert_tokens)\n",
    "\n",
    "            # 使用专家的权重对输出进行加权\n",
    "            expert_out.mul_(flat_expert_weights[idxs[start_idx:end_idx]])\n",
    "\n",
    "            # 将加权后的输出累加到 expert_cache 中\n",
    "            expert_cache.scatter_add_(0, exp_token_idx.view(-1, 1).repeat(1, x.shape[-1]), expert_out)\n",
    "\n",
    "        return expert_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61663bb8-0a39-44b3-9cd4-1f8e6b377d29",
   "metadata": {},
   "source": [
    "## 8. 完整LLaMA架构的搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff594899-bdf7-4057-935c-3807ebd15c0c",
   "metadata": {},
   "source": [
    "- **简单复习：LLaMA中的完整元素**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469cb58-96f2-4c5b-ad49-3a2705d5e816",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2024LLM/06.png\" alt=\"描述文字\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1e203-db36-429e-b985-25aba53aa321",
   "metadata": {},
   "source": [
    "- **并行化带来的影响**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecac146-42f8-495c-91c4-3379e623b046",
   "metadata": {},
   "source": [
    "搭建完整架构时、除了串联其并行化在深度学习模型的训练中至关重要，特别是当模型架构需要与 **DeepSpeed** 和 **Hugging Face** 等库的分布式训练或并行功能相结合时。为了实现这一目标，我们需要首先了解 **数据并行（Data Parallelism）** 和 **模型并行（Model Parallelism）** 这两种主要的并行方式，并明确架构中哪些关键部分与这些并行策略相关联。\n",
    "\n",
    "- 1. **数据并行与模型并行的认识**<br><br>\n",
    "   - **数据并行**：这是一种常见的并行方式，适用于将相同的模型副本应用于不同的数据切片上。例如，如果有多块 GPU，数据并行会将输入数据批次切分成多个小批次，每个 GPU 上都运行相同的模型副本，同时处理不同的数据子集。这意味着每个设备都计算自己那部分的梯度，然后将所有设备上的梯度汇总，从而对模型进行全局更新。\n",
    "   - **模型并行**：模型并行则适用于非常大的模型，这些模型可能单个设备的内存不足以容纳。模型并行通过将模型的不同部分分布在不同设备上来解决这个问题。模型的不同层或不同的部分会在不同的 GPU 上进行前向和反向传播计算。通常，模型并行用于特别大的神经网络架构，如 Transformer 或 GPT 模型。\n",
    "<br><br>\n",
    "- 2. **架构中与并行相关的关键**<br><br>\n",
    "   - **模型定义**：在设计模型时，需要确保它能够支持并行化。模型的每一层都需要使用标准的 PyTorch 模块（例如 `torch.nn.ModuleList`）来定义，这样可以确保模型在多设备上运行时保持一致性。特别是每一层的输入和输出维度必须匹配，以便于在数据并行或模型并行时正确地传播数据和梯度。你的代码中通过 `TransformerBlock` 和 `torch.nn.ModuleList` 模块化模型结构，这种设计便于并行扩展。\n",
    "   - **支持并行化**：确保模型的架构可以支持数据并行（Data Parallelism）和模型并行（Model Parallelism）。这意味着在定义时要保持各层输入输出尺寸的一致性，便于 DeepSpeed 进行分布式处理。\n",
    "<br><br>\n",
    "- 3. **与 DeepSpeed 和 Hugging Face 的结合**<br><br>\n",
    "   - **使用 Hugging Face 和 DeepSpeed 的配置文件**：在与 Hugging Face 生态系统兼容时，通常需要使用或继承 Hugging Face 的 `PreTrainedModel` 类，并确保模型定义与配置文件（config 文件）相匹配。配置文件中需要定义诸如模型的层数、嵌入维度、注意力头数等超参数，确保 Hugging Face 的 `Trainer` 工具能够正确加载和使用模型。同时，DeepSpeed 允许你通过简化模型并行和梯度计算来进行高效的分布式训练，因此在配置文件中还需要与 DeepSpeed 兼容的设置，例如启用 `zero_optim` 或 `activation checkpointing`。\n",
    "   - **分布式数据并行（DDP）**：DeepSpeed 和 Hugging Face 的分布式训练依赖于 PyTorch 的 `DistributedDataParallel`（DDP）。DDP 通过在多个 GPU 上并行处理数据来加速训练。因此，模型的定义需要支持在多机或多 GPU 环境中运行，并且模型的前向和后向传播需要能够同时在多个设备上进行。你的代码中已经通过模块化的设计方式，为 DDP 的使用提供了基础，但还需要结合 PyTorch 的 `torch.distributed.init_process_group()` 来初始化分布式进程，确保训练过程中的同步。\n",
    "<br><br>\n",
    "- 4. **权重初始化与保存**<br><br>\n",
    "   在分布式训练中，模型的保存和加载方式略有不同，特别是当使用 DeepSpeed 时，模型的检查点（checkpoint）保存和恢复需要使用其专用 API。例如，DeepSpeed 提供了 `deepspeed.save_checkpoint` 和 `deepspeed.load_checkpoint` 函数，以确保模型参数和优化器状态在分布式环境下正确存储和恢复。你的代码在初始化权重时使用了特定的初始化策略，如对 `wo.weight` 和 `w3.weight` 的正态分布初始化，这有助于保证模型的训练收敛性。 \n",
    "<br><br>\n",
    "要让模型架构能够与 **DeepSpeed** 和 **Hugging Face** 的分布式训练功能相结合，首先需要理解数据并行与模型并行的基本概念，确保模型的设计可以支持这些并行方式。模型定义时，应注意权重的共享与初始化，保证层间输入输出尺寸的兼容性。此外，合理配置模型的 `config` 文件，使其能够与 Hugging Face 的 `Trainer` 工具和 DeepSpeed 的分布式优化功能结合使用，这对于大规模模型的训练和推理至关重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d36897-982b-4865-9025-56843045e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: LMConfig):\n",
    "        \"\"\"\n",
    "        TransformerBlock 是 Transformer 模型的基础构件，包含自注意力机制、前馈网络，并根据配置使用 Mixture of Experts (MoE) 或常规前馈网络。\n",
    "\n",
    "        参数：\n",
    "        - layer_id: 当前层的编号，用于标识层。\n",
    "        - args: LMConfig 配置类，包含模型的超参数配置，如注意力头数、维度等。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads  # 注意力头的数量\n",
    "        self.dim = args.dim  # 总的模型维度\n",
    "        self.head_dim = args.dim // args.n_heads  # 每个注意力头的维度\n",
    "        self.attention = Attention(args)  # 自注意力机制模块\n",
    "\n",
    "        self.layer_id = layer_id  # 当前层的编号\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)  # 注意力层前的 RMS 归一化\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)  # 前馈网络层前的 RMS 归一化\n",
    "\n",
    "        # 根据配置判断是否使用 Mixture of Experts (MoE) 作为前馈网络\n",
    "        if args.use_moe:\n",
    "            self.feed_forward = MOEFeedForward(args)  # 使用 Mixture of Experts (MoE) 前馈网络\n",
    "        else:\n",
    "            self.feed_forward = FeedForward(  # 使用常规的前馈网络\n",
    "                dim=args.dim,  # 模型的总维度\n",
    "                hidden_dim=args.hidden_dim,  # 前馈网络隐藏层的维度\n",
    "                multiple_of=args.multiple_of,  # 隐藏层维度应为该数的倍数\n",
    "                dropout=args.dropout,  # dropout 概率，用于正则化\n",
    "            )\n",
    "\n",
    "    def forward(self, x, pos_cis, kv_cache=False):\n",
    "        \"\"\"\n",
    "        TransformerBlock 的前向传播函数。\n",
    "\n",
    "        参数：\n",
    "        - x: 输入张量。\n",
    "        - pos_cis: 位置嵌入或旋转嵌入，用于加入位置信息。\n",
    "        - kv_cache: 是否使用键值缓存（用于加速推理时）。\n",
    "\n",
    "        返回：\n",
    "        - out: Transformer Block 的输出张量。\n",
    "        \"\"\"\n",
    "        # 输入经过注意力归一化后通过自注意力层，并叠加输入\n",
    "        h = x + self.attention(self.attention_norm(x), pos_cis, kv_cache)\n",
    "        # 注意力层输出经过前馈网络归一化后通过前馈网络，并叠加输出\n",
    "        out = h + self.feed_forward(self.ffn_norm(h))\n",
    "        return out  # 返回最终输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eec5b0ba-1c51-4a44-82e6-7c7a95684857",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(PreTrainedModel):\n",
    "    config_class = LMConfig  # 定义模型使用的配置类\n",
    "    last_loss: Optional[torch.Tensor]  # 用于记录最后计算的损失值\n",
    "\n",
    "    def __init__(self, params: LMConfig = None):\n",
    "        \"\"\"\n",
    "        Transformer 是一个基于 Transformer 架构的语言模型，继承自 PreTrainedModel。\n",
    "\n",
    "        参数：\n",
    "        - params: 配置对象 LMConfig，包含模型的超参数配置。\n",
    "        \"\"\"\n",
    "        super().__init__(params)\n",
    "        if not params:\n",
    "            params = LMConfig()  # 如果没有提供配置，则使用默认配置\n",
    "        self.params = params  # 保存模型参数配置\n",
    "        self.vocab_size = params.vocab_size  # 词汇表大小\n",
    "        self.n_layers = params.n_layers  # Transformer 的层数\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)  # 词嵌入层\n",
    "        self.dropout = nn.Dropout(params.dropout)  # Dropout 层用于正则化\n",
    "        self.layers = torch.nn.ModuleList()  # TransformerBlock 的容器\n",
    "        for layer_id in range(self.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))  # 逐层添加 TransformerBlock\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)  # 最后的 RMS 正则化\n",
    "        self.output = nn.Linear(params.dim, params.vocab_size, bias=False)  # 输出层，线性映射到词汇表大小\n",
    "        self.tok_embeddings.weight = self.output.weight  # 共享词嵌入层和输出层的权重\n",
    "        pos_cis = precompute_pos_cis(self.params.dim // self.params.n_heads, self.params.max_seq_len)\n",
    "        self.register_buffer(\"pos_cis\", pos_cis, persistent=False)  # 注册位置嵌入（或旋转嵌入），不参与训练\n",
    "\n",
    "        self.apply(self._init_weights)  # 初始化模型权重\n",
    "\n",
    "        # 特殊初始化部分参数权重\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('w3.weight') or pn.endswith('wo.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02 / math.sqrt(2 * params.n_layers))\n",
    "\n",
    "        self.last_loss = None  # 初始化最后的损失为 None\n",
    "        self.OUT = CausalLMOutputWithPast()  # 初始化输出类\n",
    "        self._no_split_modules = [name for name, _ in self.named_modules()]  # 保存不拆分的模块名称\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"\n",
    "        初始化模块权重。\n",
    "        - 对线性层使用正态分布初始化权重，均值为 0，标准差为 0.02。\n",
    "        - 对词嵌入层也使用正态分布初始化权重，均值为 0，标准差为 0.02。\n",
    "        \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)  # 如果存在偏置，将偏置初始化为 0\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, tokens: Optional[torch.Tensor] = None, targets: Optional[torch.Tensor] = None,\n",
    "                kv_cache=False, **keyargs):\n",
    "        \"\"\"\n",
    "        Transformer 的前向传播函数。\n",
    "\n",
    "        参数：\n",
    "        - tokens: 输入的 token 张量，表示输入的词序列。\n",
    "        - targets: 目标张量，用于计算交叉熵损失。\n",
    "        - kv_cache: 是否使用键值缓存（用于加速推理）。\n",
    "        - keyargs: 其他可选参数，如 'input_ids' 和 'attention_mask'。\n",
    "\n",
    "        返回：\n",
    "        - 输出的 logits 和 loss（如果有目标）。\n",
    "        \"\"\"\n",
    "        current_idx = 0  # 当前索引初始化为 0\n",
    "        if 'input_ids' in keyargs:\n",
    "            tokens = keyargs['input_ids']  # 从关键字参数中提取 'input_ids'\n",
    "        if 'attention_mask' in keyargs:\n",
    "            targets = keyargs['attention_mask']  # 从关键字参数中提取 'attention_mask'\n",
    "        if 'current_idx' in keyargs:\n",
    "            current_idx = int(keyargs['current_idx'])  # 更新当前索引\n",
    "\n",
    "        _bsz, seqlen = tokens.shape  # 获取输入 tokens 的 batch 大小和序列长度\n",
    "        h = self.tok_embeddings(tokens)  # 将输入 tokens 通过词嵌入层进行嵌入\n",
    "        h = self.dropout(h)  # 通过 dropout 进行正则化\n",
    "        pos_cis = self.pos_cis[current_idx:current_idx + seqlen]  # 获取当前位置的旋转嵌入\n",
    "\n",
    "        # 逐层通过 TransformerBlock\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            h = layer(h, pos_cis, kv_cache)  # 调用每个 TransformerBlock 的前向传播\n",
    "\n",
    "        h = self.norm(h)  # 最后的 RMS 正则化处理\n",
    "\n",
    "        if targets is not None:\n",
    "            logits = self.output(h)  # 通过线性输出层生成 logits\n",
    "            # 计算交叉熵损失，忽略 index 为 0 的位置，reduction 为 'none'，即不自动求平均\n",
    "            self.last_loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1),\n",
    "                                             ignore_index=0, reduction='none')\n",
    "        else:\n",
    "            logits = self.output(h[:, [-1], :])  # 如果没有目标，只返回最后一个时间步的 logits\n",
    "            self.last_loss = None  # 没有损失\n",
    "\n",
    "        self.OUT.__setitem__('logits', logits)  # 设置输出的 logits\n",
    "        self.OUT.__setitem__('last_loss', self.last_loss)  # 设置最后的 loss\n",
    "        return self.OUT  # 返回输出对象\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def generate(self, idx, eos, max_new_tokens, temperature=0.7, top_k=8, stream=True, rp=1., kv_cache=True):\n",
    "        \"\"\"\n",
    "        推理模式下的文本生成函数。\n",
    "\n",
    "        参数：\n",
    "        - idx: 输入的 tokens。\n",
    "        - eos: 结束标志符号，当生成到 eos 时停止生成。\n",
    "        - max_new_tokens: 最大生成的新 token 数量。\n",
    "        - temperature: 控制生成的随机性，温度越高，生成越多样化。\n",
    "        - top_k: 限制 top-k 采样，控制只选择概率最高的 k 个 token。\n",
    "        - stream: 是否进行流式输出。\n",
    "        - rp: 重复惩罚系数，控制重复 token 的惩罚。\n",
    "        - kv_cache: 是否使用键值缓存来加速推理。\n",
    "\n",
    "        返回：\n",
    "        - 生成的 tokens（可能是流式返回）。\n",
    "        \"\"\"\n",
    "        index = idx.shape[1]  # 获取输入 token 序列的长度\n",
    "        init_inference = True  # 初始化推理标志\n",
    "        while idx.shape[1] < max_new_tokens - 1:  # 当生成的 tokens 长度小于最大 tokens 数时继续生成\n",
    "            if init_inference or not kv_cache:\n",
    "                inference_res, init_inference = self(idx, kv_cache=kv_cache), False  # 第一次推理，或不使用缓存\n",
    "            else:\n",
    "                inference_res = self(idx[:, -1:], kv_cache=kv_cache, current_idx=idx.shape[1] - 1)  # 仅使用最后一个 token 推理\n",
    "\n",
    "            logits = inference_res.logits  # 获取推理结果的 logits\n",
    "            logits = logits[:, -1, :]  # 只选择最后一个 token 的 logits\n",
    "\n",
    "            # 对生成的 token 进行重复惩罚\n",
    "            for token in set(idx.tolist()[0]):\n",
    "                logits[:, token] /= rp  # 对每个重复的 token 施加惩罚\n",
    "\n",
    "            if temperature == 0.0:  # 如果温度为 0，使用贪心算法选择下一个 token\n",
    "                _, idx_next = torch.topk(logits, k=1, dim=-1)\n",
    "            else:\n",
    "                logits = logits / temperature  # 根据温度调整 logits\n",
    "                if top_k is not None:\n",
    "                    v, _ = torch.topk(logits, min(top_k, logits.size(-1)))  # 使用 top-k 采样\n",
    "                    logits[logits < v[:, [-1]]] = -float('Inf')  # 排除 top-k 之外的 logits\n",
    "\n",
    "                probs = F.softmax(logits, dim=-1)  # 计算概率分布\n",
    "                idx_next = torch.multinomial(probs, num_samples=1, generator=None)  # 根据概率进行采样\n",
    "\n",
    "            if idx_next == eos:  # 如果生成了 eos token，停止生成\n",
    "                break\n",
    "\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # 将生成的 token 拼接到输入序列中\n",
    "            if stream:  # 如果启用了流式输出\n",
    "                yield idx[:, index:]  # 输出当前生成的 tokens\n",
    "\n",
    "        if not stream:  # 如果未启用流式输出\n",
    "            yield idx[:, index:]  # 返回生成的完整序列"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5184ba-2eb9-47c9-b20d-65be2abf146b",
   "metadata": {},
   "source": [
    "## 9. 配置文件的搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e807b9f8-0571-41d1-bef3-242debd65a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PretrainedConfig\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class LMConfig(PretrainedConfig):\n",
    "    model_type = \"MateConv_LlaMA\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dim: int = 512,\n",
    "            n_layers: int = 8,\n",
    "            n_heads: int = 16,\n",
    "            n_kv_heads: int = 8,\n",
    "            vocab_size: int = 6400,\n",
    "            hidden_dim: int = None,\n",
    "            multiple_of: int = 64,\n",
    "            norm_eps: float = 1e-5,\n",
    "            max_seq_len: int = 512,\n",
    "            dropout: float = 0.0,\n",
    "            flash_attn: bool = True,\n",
    "            use_moe: bool = False,\n",
    "            num_experts_per_tok=2,\n",
    "            n_routed_experts=4,\n",
    "            n_shared_experts: bool = True,\n",
    "            scoring_func='softmax',\n",
    "            aux_loss_alpha=0.01,\n",
    "            seq_aux=True,\n",
    "            norm_topk_prob=True,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        self.dim = dim\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.n_kv_heads = n_kv_heads\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.multiple_of = multiple_of\n",
    "        self.norm_eps = norm_eps\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.dropout = dropout\n",
    "        self.flash_attn = flash_attn\n",
    "        self.use_moe = use_moe\n",
    "        self.num_experts_per_tok = num_experts_per_tok  # 每个token选择的专家数量\n",
    "        self.n_routed_experts = n_routed_experts  # 总的专家数量\n",
    "        self.n_shared_experts = n_shared_experts  # 共享专家\n",
    "        self.scoring_func = scoring_func  # 评分函数，默认为softmax\n",
    "        self.aux_loss_alpha = aux_loss_alpha  # 辅助损失的alpha参数\n",
    "        self.seq_aux = seq_aux  # 是否在序列级别上计算辅助损失\n",
    "        self.norm_topk_prob = norm_topk_prob  # 是否标准化top-k概率\n",
    "        super().__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7987db8-8360-4a4b-80f9-007927b936da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from .LMConfig import LMConfig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
